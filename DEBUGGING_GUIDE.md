# üîß –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—é –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º

> **–°—Ç–∞—Ç—É—Å**: –ê–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã —Å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ–º –¥–∞–Ω–Ω—ã—Ö –ø–æ APPLICATIONID

## üö® –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–±–ª–µ–º–∞: –ù—É–ª–µ–≤–æ–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö

### –°–∏–º–ø—Ç–æ–º—ã
```
INFO:real_features_processor:‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ amplitude –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: (13439, 116)
INFO:real_features_processor:‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∑–∞—è–≤–æ–∫: (18386, 64)
INFO:real_features_processor:üéØ –¶–µ–ª–µ–≤—ã—Ö –º–µ—Ç–æ–∫: 0
ERROR:__main__:‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
```

**–î–∏–∞–≥–Ω–æ–∑**: –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ, –Ω–æ –ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ –ø–æ `APPLICATIONID` –ø–æ–ª—É—á–∞–µ—Ç—Å—è –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.

## üîç –ü–æ—à–∞–≥–æ–≤–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞

### –®–∞–≥ 1: –ó–∞–ø—É—Å–∫ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞

–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `hackathon/debug_merge.py`:

```python
#!/usr/bin/env python3
"""–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º—ã —Å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ–º –¥–∞–Ω–Ω—ã—Ö"""

import pandas as pd
from pathlib import Path
from src.real_data_loader import RealDataLoader

def analyze_applicationid_keys():
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–π APPLICATIONID"""
    
    print("üîç –ê–ù–ê–õ–ò–ó APPLICATIONID –ö–õ–Æ–ß–ï–ô")
    print("=" * 50)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    loader = RealDataLoader("data")
    
    # –ü–æ–ª—É—á–∞–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
    print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    amplitude_data = loader.load_amplitude_chunks()
    app_data = loader.load_app_data()
    target_data = loader.load_target_data()
    
    print(f"‚úÖ Amplitude: {len(amplitude_data)} –∑–∞–ø–∏—Å–µ–π")
    print(f"‚úÖ App: {len(app_data)} –∑–∞–ø–∏—Å–µ–π")
    print(f"‚úÖ Target: {len(target_data)} –∑–∞–ø–∏—Å–µ–π")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª—é—á–∏
    print("\nüîë –ê–ù–ê–õ–ò–ó –ö–õ–Æ–ß–ï–ô")
    print("-" * 30)
    
    # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ ID
    amp_ids = amplitude_data['applicationid'].dropna().astype(str).unique()
    app_ids = app_data['APPLICATIONID'].dropna().astype(str).unique()
    target_ids = target_data['APPLICATIONID'].dropna().astype(str).unique()
    
    print(f"üìà Amplitude —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö ID: {len(amp_ids)}")
    print(f"üì± App —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö ID: {len(app_ids)}")
    print(f"üéØ Target —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö ID: {len(target_ids)}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
    print("\nüìã –ü–†–ò–ú–ï–†–´ –ö–õ–Æ–ß–ï–ô")
    print("-" * 20)
    print("Amplitude –ø—Ä–∏–º–µ—Ä—ã:")
    for i, app_id in enumerate(amp_ids[:3]):
        print(f"  {i+1}. {repr(app_id)} (–¥–ª–∏–Ω–∞: {len(app_id)})")
        
    print("App –ø—Ä–∏–º–µ—Ä—ã:")
    for i, app_id in enumerate(app_ids[:3]):
        print(f"  {i+1}. {repr(app_id)} (–¥–ª–∏–Ω–∞: {len(app_id)})")
        
    print("Target –ø—Ä–∏–º–µ—Ä—ã:")
    for i, app_id in enumerate(target_ids[:3]):
        print(f"  {i+1}. {repr(app_id)} (–¥–ª–∏–Ω–∞: {len(app_id)})")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è
    print("\nüîÑ –ê–ù–ê–õ–ò–ó –ü–ï–†–ï–°–ï–ß–ï–ù–ò–ô")
    print("-" * 25)
    
    amp_set = set(amp_ids)
    app_set = set(app_ids)
    target_set = set(target_ids)
    
    amp_app = amp_set.intersection(app_set)
    app_target = app_set.intersection(target_set)
    amp_target = amp_set.intersection(target_set)
    all_three = amp_set.intersection(app_set).intersection(target_set)
    
    print(f"üìä Amplitude ‚à© App: {len(amp_app)} ID")
    print(f"üìä App ‚à© Target: {len(app_target)} ID")
    print(f"üìä Amplitude ‚à© Target: {len(amp_target)} ID")
    print(f"üìä –í—Å–µ —Ç—Ä–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞: {len(all_three)} ID")
    
    if len(all_three) > 0:
        print("\n‚úÖ –ù–ê–ô–î–ï–ù–´ –û–ë–©–ò–ï ID:")
        for app_id in list(all_three)[:5]:
            print(f"  - {repr(app_id)}")
    else:
        print("\n‚ùå –ù–ï–¢ –û–ë–©–ò–• ID!")
        
        # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ ID
        print("\nüîç –ü–û–ò–°–ö –ü–û–•–û–ñ–ò–• ID:")
        sample_amp = amp_ids[0] if len(amp_ids) > 0 else ""
        sample_app = app_ids[0] if len(app_ids) > 0 else ""
        sample_target = target_ids[0] if len(target_ids) > 0 else ""
        
        print(f"Amplitude sample: {repr(sample_amp)}")
        print(f"App sample:       {repr(sample_app)}")  
        print(f"Target sample:    {repr(sample_target)}")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏–º–≤–æ–ª—ã
        print("\nüî§ –ê–ù–ê–õ–ò–ó –°–ò–ú–í–û–õ–û–í:")
        for name, sample in [("Amplitude", sample_amp), ("App", sample_app), ("Target", sample_target)]:
            if sample:
                print(f"{name}:")
                print(f"  Raw: {repr(sample)}")
                print(f"  Bytes: {sample.encode('utf-8')}")
                print(f"  Hex: {sample.encode('utf-8').hex()}")
    
    return len(all_three) > 0

def test_normalization_approaches():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã –∫ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏"""
    
    print("\nüß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–ò")
    print("=" * 40)
    
    # –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö ID
    test_ids = [
        "–î\\286\\011639474",
        "–î\286\011639474", 
        "–î\\u00be\\u0009639474"
    ]
    
    for test_id in test_ids:
        print(f"\n–¢–µ—Å—Ç–∏—Ä—É–µ–º: {repr(test_id)}")
        
        # –ü–æ–¥—Ö–æ–¥ 1: unicode_escape
        try:
            normalized1 = test_id.encode('utf-8').decode('unicode_escape')
            print(f"  unicode_escape: {repr(normalized1)}")
        except Exception as e:
            print(f"  unicode_escape: –û–®–ò–ë–ö–ê - {e}")
            
        # –ü–æ–¥—Ö–æ–¥ 2: raw string
        try:
            normalized2 = test_id.replace('\\', '')
            print(f"  remove_backslash: {repr(normalized2)}")
        except Exception as e:
            print(f"  remove_backslash: –û–®–ò–ë–ö–ê - {e}")
            
        # –ü–æ–¥—Ö–æ–¥ 3: latin1 decode
        try:
            normalized3 = test_id.encode('latin1').decode('unicode_escape')
            print(f"  latin1_decode: {repr(normalized3)}")
        except Exception as e:
            print(f"  latin1_decode: –û–®–ò–ë–ö–ê - {e}")

if __name__ == "__main__":
    print("üöÄ –ù–ê–ß–ê–õ–û –î–ò–ê–ì–ù–û–°–¢–ò–ö–ò")
    print("=" * 50)
    
    success = analyze_applicationid_keys()
    
    if not success:
        test_normalization_approaches()
    
    print("\nüèÅ –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")
    if success:
        print("‚úÖ –ù–∞–π–¥–µ–Ω—ã –æ–±—â–∏–µ –∫–ª—é—á–∏ - –ø—Ä–æ–±–ª–µ–º–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –¥—Ä—É–≥–æ–º –º–µ—Å—Ç–µ")
    else:
        print("‚ùå –ù–µ—Ç –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –∫–ª—é—á–µ–π - –Ω—É–∂–Ω–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è")
```

–ó–∞–ø—É—Å—Ç–∏—Ç–µ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É:
```bash
cd hackathon
python debug_merge.py
```

### –®–∞–≥ 2: –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏

**–û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:**

#### –°—Ü–µ–Ω–∞—Ä–∏–π A: –ù–µ—Ç –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –∫–ª—é—á–µ–π
```
‚ùå –ù–ï–¢ –û–ë–©–ò–• ID!
üîç –ü–û–ò–°–ö –ü–û–•–û–ñ–ò–• ID:
Amplitude sample: '–î\\286\\011221568'
App sample:       '–î\\286\\011639474'
Target sample:    '–î\\286\\011639474'
```

**‚Üí –†–µ—à–µ–Ω–∏–µ**: –ù—É–∂–Ω–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è escape-—Å–∏–º–≤–æ–ª–æ–≤

#### –°—Ü–µ–Ω–∞—Ä–∏–π B: –ï—Å—Ç—å –æ–±—â–∏–µ –∫–ª—é—á–∏, –Ω–æ merge –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
```
‚úÖ –ù–ê–ô–î–ï–ù–´ –û–ë–©–ò–ï ID:
  - '–î\\286\\011639474'
üìä –í—Å–µ —Ç—Ä–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞: 1500 ID
```

**‚Üí –†–µ—à–µ–Ω–∏–µ**: –ü—Ä–æ–±–ª–µ–º–∞ –≤ –ª–æ–≥–∏–∫–µ merge, –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–µ–≥–∏—Å—Ç—Ä —Å—Ç–æ–ª–±—Ü–æ–≤

### –®–∞–≥ 3: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–ª—é—á–µ–π

–ï—Å–ª–∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–æ–∫–∞–∑–∞–ª–∞ –ø—Ä–æ–±–ª–µ–º—É —Å escape-—Å–∏–º–≤–æ–ª–∞–º–∏, –ø—Ä–∏–º–µ–Ω–∏—Ç–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ:

```python
# –í —Ñ–∞–π–ª–µ src/real_features_processor.py
# –ó–∞–º–µ–Ω–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é normalize_key –Ω–∞ —É–ª—É—á—à–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é:

def normalize_key(key):
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è APPLICATIONID"""
    if pd.isna(key) or key == '':
        return None
        
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ —Å—Ç—Ä–æ–∫–µ
    key_str = str(key).strip()
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º escape –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    # –ü—Ä–æ–±–ª–µ–º–∞: '–î\\286\\011639474' –Ω—É–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —á–∏—Ç–∞–µ–º—ã–π –≤–∏–¥
    
    try:
        # –ú–µ—Ç–æ–¥ 1: –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ unicode escape
        if '\\' in key_str:
            # –ó–∞–º–µ–Ω—è–µ–º –¥–≤–æ–π–Ω—ã–µ —Å–ª–µ—à–∏ –Ω–∞ –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏
            key_str = key_str.replace('\\\\', '\\')
            key_str = key_str.encode('utf-8', errors='ignore').decode('unicode_escape', errors='ignore')
    except Exception:
        # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –µ—Å—Ç—å
        pass
    
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –≤–µ—Ä—Ö–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –¥–ª—è –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–∏—è
    return key_str.upper().strip()
```

### –®–∞–≥ 4: –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ merge –ª–æ–≥–∏–∫–∏

–ï—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º–∞ –≤ —Å–∞–º–æ–º merge, –∑–∞–º–µ–Ω–∏—Ç–µ –ª–æ–≥–∏–∫—É –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è:

```python
# –í —Ñ–∞–π–ª–µ src/real_features_processor.py
# –í –º–µ—Ç–æ–¥–µ combine_all_features(), –∑–∞–º–µ–Ω–∏—Ç–µ –±–ª–æ–∫ merge:

# –°–¢–ê–†–´–ô –ö–û–î (–ø—Ä–æ–±–ª–µ–º–Ω—ã–π):
final_data = pd.merge(
    combined_features, target_data,
    left_on='applicationid', right_on=merge_col,
    how='inner'
)

# –ù–û–í–´–ô –ö–û–î (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π):
# –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–ª—é—á–∏ –≤ –æ–±–µ–∏—Ö —Ç–∞–±–ª–∏—Ü–∞—Ö
combined_features['app_id_normalized'] = combined_features['applicationid'].apply(normalize_key)
target_data['app_id_normalized'] = target_data[merge_col].apply(normalize_key)

# –£–±–∏—Ä–∞–µ–º None –∑–Ω–∞—á–µ–Ω–∏—è
combined_features = combined_features[combined_features['app_id_normalized'].notna()]
target_data = target_data[target_data['app_id_normalized'].notna()]

# –í—ã–ø–æ–ª–Ω—è–µ–º merge –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º –∫–ª—é—á–∞–º
final_data = pd.merge(
    combined_features, target_data,
    left_on='app_id_normalized', right_on='app_id_normalized',
    how='inner'
)

# –û—á–∏—â–∞–µ–º –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
final_data = final_data.drop(columns=['app_id_normalized'], errors='ignore')

logger.info(f"üîç –ó–∞–ø–∏—Å–µ–π –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ merge: {len(final_data)}")
```

### –®–∞–≥ 5: –í–∞–ª–∏–¥–∞—Ü–∏—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è

–°–æ–∑–¥–∞–π—Ç–µ –ø—Ä–æ–≤–µ—Ä–æ—á–Ω—ã–π —Å–∫—Ä–∏–ø—Ç `hackathon/validate_fix.py`:

```python
#!/usr/bin/env python3
"""–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º—ã"""

from src.real_features_processor import RealFeaturesProcessor
import pandas as pd

def validate_merge_fix():
    """–ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç"""
    
    print("üß™ –í–ê–õ–ò–î–ê–¶–ò–Ø –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø")
    print("=" * 40)
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
        processor = RealFeaturesProcessor("data")
        
        # –ü—Ä–æ–±—É–µ–º –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
        print("üìä –í—ã–ø–æ–ª–Ω—è–µ–º combine_all_features()...")
        X, y = processor.combine_all_features()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        print(f"üìà –§–æ—Ä–º–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ X: {X.shape}")
        print(f"üéØ –†–∞–∑–º–µ—Ä —Ü–µ–ª–µ–≤—ã—Ö –º–µ—Ç–æ–∫ y: {len(y)}")
        
        if X.empty or y.empty:
            print("‚ùå –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ù–ï –°–†–ê–ë–û–¢–ê–õ–û - –¥–∞–Ω–Ω—ã–µ –≤—Å–µ –µ—â–µ –ø—É—Å—Ç—ã–µ")
            return False
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤
        class_dist = y.value_counts()
        print(f"üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {class_dist.to_dict()}")
        
        fraud_rate = y.mean()
        print(f"üìà –î–æ–ª—è –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞: {fraud_rate:.2%}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        null_counts = X.isnull().sum().sum()
        inf_counts = X.select_dtypes(include=['number']).apply(lambda x: x.isin([float('inf'), float('-inf')]).sum()).sum()
        
        print(f"üîç –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: {null_counts}")
        print(f"üîç –ë–µ—Å–∫–æ–Ω–µ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: {inf_counts}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        print(f"üìã –ü–µ—Ä–≤—ã–µ 5 –∫–æ–ª–æ–Ω–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {list(X.columns[:5])}")
        print(f"üìã –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 –∫–æ–ª–æ–Ω–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {list(X.columns[-5:])}")
        
        print("\n‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –£–°–ü–ï–®–ù–û!")
        print(f"‚úÖ –ì–æ—Ç–æ–≤–æ {len(y)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û–®–ò–ë–ö–ê –ü–†–ò –í–ê–õ–ò–î–ê–¶–ò–ò: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_model_training():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    
    print("\nü§ñ –¢–ï–°–¢ –û–ë–£–ß–ï–ù–ò–Ø –ú–û–î–ï–õ–ò")
    print("=" * 30)
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        processor = RealFeaturesProcessor("data")
        X, y = processor.combine_all_features()
        
        if X.empty or y.empty:
            print("‚ùå –ù–µ–ª—å–∑—è –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å - –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
            return False
        
        # –ü—Ä–æ–±—É–µ–º –æ–±—É—á–∏—Ç—å –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å
        from sklearn.ensemble import RandomForestClassifier
        from sklearn.model_selection import train_test_split
        from sklearn.metrics import classification_report, roc_auc_score
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        print(f"üìä –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_train.shape}")
        print(f"üìä –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_test.shape}")
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        print("üèãÔ∏è –û–±—É—á–µ–Ω–∏–µ Random Forest...")
        model = RandomForestClassifier(
            n_estimators=50,  # –£–º–µ–Ω—å—à–∏–ª–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ—Ç—ã
            max_depth=5,
            class_weight='balanced',
            random_state=42,
            n_jobs=-1
        )
        
        model.fit(X_train, y_train)
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
        y_pred = model.predict(X_test)
        y_pred_proba = model.predict_proba(X_test)[:, 1]
        
        auc_score = roc_auc_score(y_test, y_pred_proba)
        print(f"üìà AUC-ROC: {auc_score:.3f}")
        
        print("\nüìä –û—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
        print(classification_report(y_test, y_pred))
        
        # –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        feature_importance = pd.DataFrame({
            'feature': X.columns,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print("\nüéØ –¢–æ–ø-10 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
        print(feature_importance.head(10))
        
        print("\n‚úÖ –ú–û–î–ï–õ–¨ –£–°–ü–ï–®–ù–û –û–ë–£–ß–ï–ù–ê!")
        return True
        
    except Exception as e:
        print(f"‚ùå –û–®–ò–ë–ö–ê –ü–†–ò –û–ë–£–ß–ï–ù–ò–ò: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("üöÄ –ù–ê–ß–ê–õ–û –í–ê–õ–ò–î–ê–¶–ò–ò")
    print("=" * 50)
    
    # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
    merge_ok = validate_merge_fix()
    
    if merge_ok:
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–±—É—á–µ–Ω–∏–µ
        model_ok = test_model_training()
        
        if model_ok:
            print("\nüéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´!")
            print("‚úÖ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–º—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")
        else:
            print("\n‚ö†Ô∏è –î–∞–Ω–Ω—ã–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã, –Ω–æ –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã —Å –º–æ–¥–µ–ª—å—é")
    else:
        print("\n‚ùå –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ù–ï –ü–û–ú–û–ì–õ–û")
        print("–ù—É–∂–Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞")
    
    print("\nüèÅ –í–ê–õ–ò–î–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê")
```

–ó–∞–ø—É—Å—Ç–∏—Ç–µ –≤–∞–ª–∏–¥–∞—Ü–∏—é:
```bash
python validate_fix.py
```

## üõ†Ô∏è –†–µ–∑–µ—Ä–≤–Ω—ã–µ –ø–ª–∞–Ω—ã –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è

### –ü–ª–∞–Ω B: –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–ª—é—á–µ–π

–ï—Å–ª–∏ –ø–æ–ª–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —á–∞—Å—Ç–∏—á–Ω–æ–µ:

```python
def fuzzy_merge_applicationid(df1, df2, key1, key2, threshold=0.8):
    """–ù–µ—á–µ—Ç–∫–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ APPLICATIONID"""
    from difflib import SequenceMatcher
    
    # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª—é—á–∏
    keys1 = df1[key1].dropna().unique()
    keys2 = df2[key2].dropna().unique()
    
    # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –∫–ª—é—á–∏
    matches = []
    for k1 in keys1:
        for k2 in keys2:
            similarity = SequenceMatcher(None, str(k1), str(k2)).ratio()
            if similarity >= threshold:
                matches.append((k1, k2, similarity))
    
    print(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(matches)} –Ω–µ—á–µ—Ç–∫–∏—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π")
    
    # –°–æ–∑–¥–∞–µ–º –º–∞–ø–ø–∏–Ω–≥
    key_mapping = {k1: k2 for k1, k2, _ in matches}
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∞–ø–ø–∏–Ω–≥
    df1_mapped = df1.copy()
    df1_mapped[key1 + '_mapped'] = df1_mapped[key1].map(key_mapping)
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º merge
    result = pd.merge(
        df1_mapped, df2,
        left_on=key1 + '_mapped', right_on=key2,
        how='inner'
    )
    
    return result.drop(columns=[key1 + '_mapped'])
```

### –ü–ª–∞–Ω C: –í—Ä–µ–º–µ–Ω–Ω–∞—è –ø—Ä–∏–≤—è–∑–∫–∞

–ï—Å–ª–∏ ID –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–≤—è–∑–∞—Ç—å –ø–æ –≤—Ä–µ–º–µ–Ω–∏:

```python
def temporal_merge(amplitude_data, app_data, time_window_hours=24):
    """–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –±–ª–∏–∑–æ—Å—Ç–∏"""
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –¥–∞—Ç—ã
    amplitude_data['event_date'] = pd.to_datetime(amplitude_data['event_time']).dt.date
    app_data['create_date'] = pd.to_datetime(app_data['CREATE_DATE']).dt.date
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø–æ –¥–∞—Ç–∞–º —Å –æ–∫–Ω–æ–º
    merged_records = []
    
    for _, app_row in app_data.iterrows():
        create_date = app_row['create_date']
        
        # –ò—â–µ–º amplitude –∑–∞–ø–∏—Å–∏ –≤ –æ–∫–Ω–µ –≤—Ä–µ–º–µ–Ω–∏
        date_range = pd.date_range(
            start=create_date - pd.Timedelta(days=1),
            end=create_date + pd.Timedelta(days=1)
        ).date
        
        matching_amp = amplitude_data[
            amplitude_data['event_date'].isin(date_range)
        ]
        
        if not matching_amp.empty:
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –ø–æ–¥—Ö–æ–¥—è—â—É—é –∑–∞–ø–∏—Å—å
            merged_record = {**app_row.to_dict(), **matching_amp.iloc[0].to_dict()}
            merged_records.append(merged_record)
    
    return pd.DataFrame(merged_records)
```

### –ü–ª–∞–Ω D: –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç–æ–∫

–î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã –º–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ —Ü–µ–ª–µ–≤—ã–µ –º–µ—Ç–∫–∏:

```python
def create_synthetic_targets(features_df, fraud_rate=0.02):
    """–°–æ–∑–¥–∞–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ —Ü–µ–ª–µ–≤—ã–µ –º–µ—Ç–∫–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    import numpy as np
    
    n_samples = len(features_df)
    n_fraud = int(n_samples * fraud_rate)
    
    # –°–æ–∑–¥–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –º–µ—Ç–∫–∏ —Å –∑–∞–¥–∞–Ω–Ω–æ–π –¥–æ–ª–µ–π –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞
    targets = np.zeros(n_samples)
    fraud_indices = np.random.choice(n_samples, size=n_fraud, replace=False)
    targets[fraud_indices] = 1
    
    print(f"üéØ –°–æ–∑–¥–∞–Ω–æ {n_fraud} —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç–æ–∫ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞ –∏–∑ {n_samples}")
    
    return pd.Series(targets, index=features_df.index)
```

## üìã –ß–µ–∫-–ª–∏—Å—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è

### –ü–µ—Ä–µ–¥ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º:
- [ ] –°–æ–∑–¥–∞–Ω backup –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
- [ ] –ó–∞–ø—É—â–µ–Ω–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ `debug_merge.py`
- [ ] –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –ø—Ä–∏—á–∏–Ω–∞ –ø—Ä–æ–±–ª–µ–º—ã
- [ ] –í—ã–±—Ä–∞–Ω –ø–æ–¥—Ö–æ–¥—è—â–∏–π –ø–ª–∞–Ω –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è

### –í–æ –≤—Ä–µ–º—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:
- [ ] –ü—Ä–∏–º–µ–Ω–µ–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ `normalize_key()` —Ñ—É–Ω–∫—Ü–∏–∏
- [ ] –û–±–Ω–æ–≤–ª–µ–Ω–∞ –ª–æ–≥–∏–∫–∞ merge –≤ `combine_all_features()`
- [ ] –î–æ–±–∞–≤–ª–µ–Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
- [ ] –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

### –ü–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:
- [ ] –ó–∞–ø—É—â–µ–Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—è `validate_fix.py`
- [ ] –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ —á—Ç–æ `X.shape[0] > 0` –∏ `len(y) > 0`
- [ ] –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ —Ü–µ–ª–µ–≤—ã—Ö –º–µ—Ç–∫–∞—Ö
- [ ] –£—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞ —Ç–µ—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å
- [ ] –ó–∞–ø—É—â–µ–Ω –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω `train_real_data.py`

## üîî –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Ç–æ—á–∫–∏

### –£—Å–ø–µ—à–Ω–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ:
```
‚úÖ –î–∞–Ω–Ω—ã–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã: (15000, 200) –∑–∞–ø–∏—Å–µ–π
‚úÖ –¶–µ–ª–µ–≤—ã–µ –º–µ—Ç–∫–∏: 15000 –∑–∞–ø–∏—Å–µ–π  
‚úÖ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {0: 14700, 1: 300}
‚úÖ –î–æ–ª—è –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞: 2.00%
‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞, AUC-ROC: 0.857
```

### –ù–µ–ø–æ–ª–Ω–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ:
```
‚ö†Ô∏è –î–∞–Ω–Ω—ã–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã: (500, 200) –∑–∞–ø–∏—Å–µ–π  ‚Üê –°–ª–∏—à–∫–æ–º –º–∞–ª–æ
‚ö†Ô∏è –¶–µ–ª–µ–≤—ã–µ –º–µ—Ç–∫–∏: 500 –∑–∞–ø–∏—Å–µ–π
‚ö†Ô∏è –î–æ–ª—è –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞: 0.20%  ‚Üê –°–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∞—è –¥–æ–ª—è
```

### –ù–µ—É–¥–∞—á–Ω–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ:
```
‚ùå –§–æ—Ä–º–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ X: (0, 0)
‚ùå –†–∞–∑–º–µ—Ä —Ü–µ–ª–µ–≤—ã—Ö –º–µ—Ç–æ–∫ y: 0
‚ùå –î–∞–Ω–Ω—ã–µ –≤—Å–µ –µ—â–µ –ø—É—Å—Ç—ã–µ
```

## üìû –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∏ –ø–æ–º–æ—â—å

### –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–º–æ–≥–∞–µ—Ç:

1. **–°–æ–∑–¥–∞–π—Ç–µ –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç**:
   ```bash
   python debug_merge.py > debug_report.txt 2>&1
   python validate_fix.py > validation_report.txt 2>&1
   ```

2. **–°–æ–±–µ—Ä–∏—Ç–µ –æ–±—Ä–∞–∑—Ü—ã –¥–∞–Ω–Ω—ã—Ö**:
   ```python
   # –°–æ–∑–¥–∞–π—Ç–µ samples.py
   from src.real_data_loader import RealDataLoader
   
   loader = RealDataLoader("data")
   
   # –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ –æ–±—Ä–∞–∑—Ü—ã
   amplitude_sample = loader.load_amplitude_chunks().head(10)
   app_sample = loader.load_app_data().head(10)
   target_sample = loader.load_target_data().head(10)
   
   amplitude_sample.to_csv("amplitude_sample.csv")
   app_sample.to_csv("app_sample.csv")  
   target_sample.to_csv("target_sample.csv")
   ```

3. **–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è**:
   - Python >= 3.8
   - pandas >= 1.5.0
   - –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ RAM (8GB+)
   - –ö–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ —Ñ–∞–π–ª–∞–º

---

**üéØ –¶–µ–ª—å**: –ü–æ–ª—É—á–∏—Ç—å —Ä–∞–±–æ—á–∏–π –¥–∞—Ç–∞—Å–µ—Ç —Å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏ —Ü–µ–ª–µ–≤—ã–º–∏ –º–µ—Ç–∫–∞–º–∏ –¥–ª—è —É—Å–ø–µ—à–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∞–Ω—Ç–∏—Ñ—Ä–æ–¥ –º–æ–¥–µ–ª–∏.

**‚úÖ –ö—Ä–∏—Ç–µ—Ä–∏–π —É—Å–ø–µ—Ö–∞**: `X.shape[0] > 10000` –∏ `len(y) > 10000` —Å –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∫–ª–∞—Å—Å–æ–≤.