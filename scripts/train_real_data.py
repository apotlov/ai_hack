#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è –∞–Ω—Ç–∏—Ñ—Ä–æ–¥ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
"""

import sys
import os
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append(str(Path(__file__).parent.parent / "src"))

import logging
import pandas as pd
import numpy as np
from tqdm import tqdm
from typing import Dict, Any

from real_features_processor import RealFeaturesProcessor
from model_trainer import ModelTrainer

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def validate_data_structure(data_dir: Path) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è

    Args:
        data_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –¥–∞–Ω–Ω—ã–º–∏

    Returns:
        True –µ—Å–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞
    """
    logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö...")

    amplitude_dir = data_dir / "amplitude"
    audio_dir = data_dir / "audiofiles"

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    required_files = [
        "train_target_data.parquet",  # –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    ]

    missing_files = []
    for file_name in required_files:
        file_path = amplitude_dir / file_name
        if not file_path.exists():
            missing_files.append(file_name)

    if missing_files:
        logger.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã: {missing_files}")
        return False

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º amplitude —á–∞–Ω–∫–∏
    amplitude_chunks = list(amplitude_dir.glob("train_amplitude_chunk_*.parquet"))
    if not amplitude_chunks:
        logger.warning("‚ö†Ô∏è  Amplitude —á–∞–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –Ω–æ —ç—Ç–æ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ")
    else:
        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ amplitude —á–∞–Ω–∫–æ–≤: {len(amplitude_chunks)}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞—è–≤–æ–∫
    app_data_file = amplitude_dir / "train_app_data.parquet"
    if app_data_file.exists():
        logger.info("‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞—è–≤–æ–∫ –Ω–∞–π–¥–µ–Ω—ã")
    else:
        logger.warning("‚ö†Ô∏è  –î–∞–Ω–Ω—ã–µ –∑–∞—è–≤–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—É–¥–∏–æ—Ñ–∞–π–ª—ã
    if audio_dir.exists():
        audio_files = list(audio_dir.glob("*.wav"))
        logger.info(f"üéµ –ù–∞–π–¥–µ–Ω–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤: {len(audio_files)}")
    else:
        logger.warning("‚ö†Ô∏è  –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

    return True


def analyze_data_quality(X: pd.DataFrame, y: pd.Series) -> Dict[str, Any]:
    """
    –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö

    Args:
        X: –ü—Ä–∏–∑–Ω–∞–∫–∏
        y: –¶–µ–ª–µ–≤—ã–µ –º–µ—Ç–∫–∏

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    """
    logger.info("üìä –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö...")

    quality_metrics = {}

    # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    quality_metrics.update({
        'samples_count': len(X),
        'features_count': X.shape[1],
        'target_distribution': y.value_counts().to_dict(),
        'fraud_rate': y.mean(),
        'missing_values_ratio': X.isnull().sum().sum() / (X.shape[0] * X.shape[1])
    })

    # –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    numeric_features = X.select_dtypes(include=[np.number]).columns
    categorical_features = X.select_dtypes(include=['object']).columns

    quality_metrics.update({
        'numeric_features_count': len(numeric_features),
        'categorical_features_count': len(categorical_features)
    })

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    constant_features = X.columns[X.nunique() <= 1]
    quality_metrics['constant_features_count'] = len(constant_features)

    # –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å –≤—ã—Å–æ–∫–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–æ–ø—É—Å–∫–æ–≤
    high_missing_features = X.columns[X.isnull().sum() / len(X) > 0.5]
    quality_metrics['high_missing_features_count'] = len(high_missing_features)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤
    if len(y.value_counts()) == 2:
        minority_class_ratio = y.value_counts().min() / len(y)
        quality_metrics['minority_class_ratio'] = minority_class_ratio
        quality_metrics['is_balanced'] = minority_class_ratio >= 0.3

    # –õ–æ–≥–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    logger.info(f"üìà –û–±—Ä–∞–∑—Ü–æ–≤: {quality_metrics['samples_count']}")
    logger.info(f"üìä –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {quality_metrics['features_count']}")
    logger.info(f"üéØ –î–æ–ª—è –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞: {quality_metrics['fraud_rate']:.2%}")
    logger.info(f"üîç –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {quality_metrics['missing_values_ratio']:.2%}")

    if quality_metrics.get('is_balanced', True):
        logger.info("‚úÖ –ö–ª–∞—Å—Å—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã")
    else:
        logger.warning(f"‚ö†Ô∏è  –î–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤: {quality_metrics['minority_class_ratio']:.2%}")

    return quality_metrics


def prepare_training_data(features_processor: RealFeaturesProcessor) -> tuple:
    """
    –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è

    Args:
        features_processor: –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

    Returns:
        –ö–æ—Ä—Ç–µ–∂ (X, y, metadata)
    """
    logger.info("üîß –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è...")

    with tqdm(total=4, desc="üîß –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö", unit="—à–∞–≥", leave=False) as pbar:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        pbar.set_description("üîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        X, y = features_processor.combine_all_features()
        pbar.update(1)

        if X.empty or y.empty:
            raise ValueError("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")

        # –£–¥–∞–ª—è–µ–º session_id –∏–∑ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
        pbar.set_description("üßπ –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
        if 'session_id' in X.columns:
            X = X.drop('session_id', axis=1)
        pbar.update(1)

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
        pbar.set_description("üìä –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞")
        quality_metrics = analyze_data_quality(X, y)
        pbar.update(1)

        # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
        pbar.set_description("‚ö†Ô∏è  –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞")
        if quality_metrics['missing_values_ratio'] > 0.2:
            logger.warning("‚ö†Ô∏è  –í—ã—Å–æ–∫–∞—è –¥–æ–ª—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")

        if quality_metrics['fraud_rate'] < 0.05:
            logger.warning("‚ö†Ô∏è  –û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è –¥–æ–ª—è –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞")
        elif quality_metrics['fraud_rate'] > 0.5:
            logger.warning("‚ö†Ô∏è  –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –≤—ã—Å–æ–∫–∞—è –¥–æ–ª—è –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞")
        pbar.update(1)

    return X, y, quality_metrics


def train_antifraud_model(X: pd.DataFrame, y: pd.Series,
                         models_dir: Path, quality_metrics: Dict) -> Dict[str, Any]:
    """
    –û–±—É—á–µ–Ω–∏–µ –∞–Ω—Ç–∏—Ñ—Ä–æ–¥ –º–æ–¥–µ–ª–∏

    Args:
        X: –ü—Ä–∏–∑–Ω–∞–∫–∏
        y: –¶–µ–ª–µ–≤—ã–µ –º–µ—Ç–∫–∏
        models_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
        quality_metrics: –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è
    """
    logger.info("ü§ñ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –∞–Ω—Ç–∏—Ñ—Ä–æ–¥ –º–æ–¥–µ–ª–∏...")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç—Ä–µ–Ω–µ—Ä–∞ –º–æ–¥–µ–ª–∏
    model_trainer = ModelTrainer(str(models_dir))

    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –¥–∞–Ω–Ω—ã—Ö
    if quality_metrics['fraud_rate'] < 0.1:
        # –î–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        from sklearn.ensemble import RandomForestClassifier
        model_trainer.model = RandomForestClassifier(
            n_estimators=200,
            max_depth=15,
            min_samples_split=10,
            min_samples_leaf=5,
            class_weight='balanced',  # –í–∞–∂–Ω–æ –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            random_state=42,
            n_jobs=-1
        )
        logger.info("üéØ –ù–∞—Å—Ç—Ä–æ–µ–Ω–∞ –º–æ–¥–µ–ª—å –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")

    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    metrics = model_trainer.train(X, y, test_size=0.2)

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è –∞–Ω—Ç–∏—Ñ—Ä–æ–¥ –º–æ–¥–µ–ª–∏
    additional_metrics = validate_antifraud_model(model_trainer, X, y, quality_metrics)
    metrics.update(additional_metrics)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    model_name = "real_antifraud_model"
    model_trainer.save_model(model_name)

    logger.info(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_name}")

    return metrics


def validate_antifraud_model(model_trainer: ModelTrainer, X: pd.DataFrame,
                           y: pd.Series, quality_metrics: Dict) -> Dict[str, Any]:
    """
    –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –∞–Ω—Ç–∏—Ñ—Ä–æ–¥ –º–æ–¥–µ–ª–∏

    Args:
        model_trainer: –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        X: –ü—Ä–∏–∑–Ω–∞–∫–∏
        y: –¶–µ–ª–µ–≤—ã–µ –º–µ—Ç–∫–∏
        quality_metrics: –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö

    Returns:
        –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    """
    logger.info("üîç –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏...")

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –ø–æ–ª–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ
    y_pred = model_trainer.predict(X)
    y_pred_proba = model_trainer.predict_proba(X)[:, 1]

    # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è –∞–Ω—Ç–∏—Ñ—Ä–æ–¥ –º–µ—Ç—Ä–∏–∫–∏
    from sklearn.metrics import precision_recall_curve, average_precision_score

    precision, recall, thresholds = precision_recall_curve(y, y_pred_proba)
    avg_precision = average_precision_score(y, y_pred_proba)

    # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ä–∞–∑–Ω—ã–º –ø–æ—Ä–æ–≥–∞–º
    high_precision_threshold = None
    for i, (p, r, t) in enumerate(zip(precision, recall, thresholds)):
        if p >= 0.8:  # –ò—â–µ–º –ø–æ—Ä–æ–≥ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏ 80%+
            high_precision_threshold = t
            break

    additional_metrics = {
        'avg_precision_score': avg_precision,
        'high_precision_threshold': high_precision_threshold,
        'fraud_detection_rate_at_80_precision': recall[precision >= 0.8][0] if any(precision >= 0.8) else 0
    }

    # –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    feature_importance = model_trainer.get_feature_importance(top_n=20)
    if not feature_importance.empty:
        additional_metrics['top_features'] = feature_importance.head(10)['feature'].tolist()

    return additional_metrics


def create_training_report(metrics: Dict[str, Any], quality_metrics: Dict[str, Any],
                         output_dir: Path) -> None:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ–± –æ–±—É—á–µ–Ω–∏–∏

    Args:
        metrics: –ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏
        quality_metrics: –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞
    """
    logger.info("üìÑ –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ–± –æ–±—É—á–µ–Ω–∏–∏...")

    report_content = f"""
=== –û–¢–ß–ï–¢ –û–ë –û–ë–£–ß–ï–ù–ò–ò –ê–ù–¢–ò–§–†–û–î –ú–û–î–ï–õ–ò ===
–î–∞—Ç–∞: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}

–ö–ê–ß–ï–°–¢–í–û –î–ê–ù–ù–´–•:
- –û–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {quality_metrics['samples_count']:,}
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {quality_metrics['features_count']:,}
- –î–æ–ª—è –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞: {quality_metrics['fraud_rate']:.2%}
- –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {quality_metrics['missing_values_ratio']:.2%}
- –ß–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {quality_metrics['numeric_features_count']:,}
- –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {quality_metrics['categorical_features_count']:,}

–†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ë–£–ß–ï–ù–ò–Ø:
- –†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {metrics.get('train_size', 'N/A'):,}
- –†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {metrics.get('test_size', 'N/A'):,}

–ú–ï–¢–†–ò–ö–ò –ö–ê–ß–ï–°–¢–í–ê –ú–û–î–ï–õ–ò:
- Test Accuracy: {metrics.get('test_accuracy', 0):.4f}
- Test Precision: {metrics.get('test_precision', 0):.4f}
- Test Recall: {metrics.get('test_recall', 0):.4f}
- Test F1-Score: {metrics.get('test_f1', 0):.4f}
- Test AUC-ROC: {metrics.get('test_auc', 0):.4f}
- Average Precision: {metrics.get('avg_precision_score', 0):.4f}

–ö–†–û–°–°-–í–ê–õ–ò–î–ê–¶–ò–Ø:
- CV AUC (—Å—Ä–µ–¥–Ω–µ–µ): {metrics.get('cv_auc_mean', 0):.4f}
- CV AUC (—Å—Ç–¥. –æ—Ç–∫–ª.): {metrics.get('cv_auc_std', 0):.4f}

–ê–ù–¢–ò–§–†–û–î –°–ü–ï–¶–ò–§–ò–ß–ù–´–ï –ú–ï–¢–†–ò–ö–ò:
- –ü–æ—Ä–æ–≥ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏ 80%: {metrics.get('high_precision_threshold', 'N/A')}
- Recall –ø—Ä–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏ 80%: {metrics.get('fraud_detection_rate_at_80_precision', 0):.4f}

–í–ê–ñ–ù–ï–ô–®–ò–ï –ü–†–ò–ó–ù–ê–ö–ò:
"""

    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ø –ø—Ä–∏–∑–Ω–∞–∫–∏
    if 'top_features' in metrics:
        for i, feature in enumerate(metrics['top_features'], 1):
            report_content += f"{i:2d}. {feature}\n"

    report_content += f"""

–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ:
"""

    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    if metrics.get('test_auc', 0) >= 0.85:
        report_content += "‚úÖ –ú–æ–¥–µ–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ (AUC ‚â• 0.85)\n"
    elif metrics.get('test_auc', 0) >= 0.75:
        report_content += "‚ö†Ô∏è  –ú–æ–¥–µ–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ö–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ (AUC ‚â• 0.75)\n"
    else:
        report_content += "‚ùå –ú–æ–¥–µ–ª—å —Ç—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è (AUC < 0.75)\n"

    if quality_metrics.get('fraud_rate', 0) < 0.05:
        report_content += "‚ö†Ô∏è  –ù–∏–∑–∫–∞—è –¥–æ–ª—è –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞ - —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –º–µ—Ç–æ–¥—ã –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏\n"

    if quality_metrics.get('missing_values_ratio', 0) > 0.2:
        report_content += "‚ö†Ô∏è  –í—ã—Å–æ–∫–∞—è –¥–æ–ª—è –ø—Ä–æ–ø—É—Å–∫–æ–≤ - —É–ª—É—á—à–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö\n"

    report_content += """
–°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò:
1. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –º–æ–¥–µ–ª—å –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
2. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–æ—Ä–æ–≥–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –±–∏–∑–Ω–µ—Å-—Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
3. –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ
4. –†–µ–≥—É–ª—è—Ä–Ω–æ –ø–µ—Ä–µ–æ–±—É—á–∞–π—Ç–µ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö

=== –ö–û–ù–ï–¶ –û–¢–ß–ï–¢–ê ===
"""

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
    report_file = output_dir / "training_report.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report_content)

    logger.info(f"üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}")


def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    """
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –∞–Ω—Ç–∏—Ñ—Ä–æ–¥ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")

    try:
        # –û–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å –¥–ª—è –≤—Å–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞
        with tqdm(total=7, desc="üöÄ –û–±—É—á–µ–Ω–∏–µ –∞–Ω—Ç–∏—Ñ—Ä–æ–¥ –º–æ–¥–µ–ª–∏", unit="—ç—Ç–∞–ø", position=0) as main_pbar:

            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—É—Ç–µ–π
            main_pbar.set_description("üìÇ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π")
            data_dir = Path(__file__).parent.parent / "data"
            models_dir = Path(__file__).parent.parent / "models"
            output_dir = Path(__file__).parent.parent / "output"

            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            models_dir.mkdir(exist_ok=True)
            output_dir.mkdir(exist_ok=True)

            logger.info(f"üìÇ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–∞–Ω–Ω—ã—Ö: {data_dir}")
            logger.info(f"ü§ñ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –º–æ–¥–µ–ª–µ–π: {models_dir}")
            logger.info(f"üìä –í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {output_dir}")
            main_pbar.update(1)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
            main_pbar.set_description("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
            if not validate_data_structure(data_dir):
                logger.error("‚ùå –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –Ω–µ –ø—Ä–æ–π–¥–µ–Ω–∞")
                return False
            main_pbar.update(1)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        logger.info("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        features_processor = RealFeaturesProcessor(str(data_dir))

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        main_pbar.set_description("üîß –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
        X, y, quality_metrics = prepare_training_data(features_processor)
        main_pbar.update(1)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
        main_pbar.set_description("‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
        if len(X) < 100:
            logger.error("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (–º–∏–Ω–∏–º—É–º 100 –æ–±—Ä–∞–∑—Ü–æ–≤)")
            return False

        # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
        logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö...")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ —á–∏—Å–ª–æ–≤—ã–µ
        non_numeric_cols = []
        for col in X.columns:
            if X[col].dtype == 'object':
                non_numeric_cols.append(col)
                logger.warning(f"‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–∞ –Ω–µ—á–∏—Å–ª–æ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞: {col} (—Ç–∏–ø: {X[col].dtype})")

        if non_numeric_cols:
            logger.error(f"‚ùå –ù–∞–π–¥–µ–Ω—ã –Ω–µ—á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {non_numeric_cols}")
            logger.info("üîß –ü–æ–ø—ã—Ç–∫–∞ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è...")

            for col in non_numeric_cols:
                try:
                    X[col] = pd.to_numeric(X[col], errors='coerce')
                    X[col] = X[col].fillna(0)
                    logger.info(f"‚úÖ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞: {col}")
                except Exception as e:
                    logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å {col}: {e}")
                    X = X.drop(columns=[col])
                    logger.info(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω–∞ –ø—Ä–æ–±–ª–µ–º–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞: {col}")

        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        remaining_object_cols = X.select_dtypes(include=['object']).columns
        if len(remaining_object_cols) > 0:
            logger.error(f"‚ùå –û—Å—Ç–∞–ª–∏—Å—å –Ω–µ—á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(remaining_object_cols)}")
            X = X.select_dtypes(exclude=['object'])
            logger.info(f"üîß –£–¥–∞–ª–µ–Ω—ã –≤—Å–µ –Ω–µ—á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏, –æ—Å—Ç–∞–ª–æ—Å—å: {X.shape}")

        logger.info(f"‚úÖ –§–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {X.shape}, –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ —á–∏—Å–ª–æ–≤—ã–µ")
        main_pbar.update(1)

        if y.nunique() < 2:
            logger.error("‚ùå –ù–µ—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –≤ —Ü–µ–ª–µ–≤—ã—Ö –º–µ—Ç–∫–∞—Ö")
            return False

        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        training_metrics = train_antifraud_model(X, y, models_dir, quality_metrics)

        # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç
        create_training_report(training_metrics, quality_metrics, output_dir)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        training_data_path = output_dir / "training_data_summary.csv"
        X_summary = X.describe()
        X_summary.to_csv(training_data_path)

        # –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        logger.info("\n" + "="*60)
        logger.info("‚úÖ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û!")
        logger.info("="*60)
        logger.info(f"üìä –û–±—É—á–µ–Ω–æ –Ω–∞ {len(X):,} –æ–±—Ä–∞–∑—Ü–∞—Ö")
        logger.info(f"üéØ –î–æ–ª—è –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞: {y.mean():.2%}")
        logger.info(f"üìà Test AUC: {training_metrics.get('test_auc', 0):.4f}")
        logger.info(f"üéØ Test F1: {training_metrics.get('test_f1', 0):.4f}")
        logger.info(f"üíæ –ú–æ–¥–µ–ª—å: real_antifraud_model")
        logger.info("="*60)

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Å–ª–µ–¥—É—é—â–∏–º —à–∞–≥–∞–º
        logger.info("\nüí° –°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò:")
        logger.info("1. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –º–æ–¥–µ–ª—å:")
        logger.info("   python scripts/predict_real_data.py")
        logger.info("2. –î–æ–±–∞–≤—å—Ç–µ LLM –æ–±—ä—è—Å–Ω–µ–Ω–∏—è:")
        logger.info("   python scripts/predict_local_llm.py")
        logger.info("3. –ü—Ä–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –æ—Ç—á–µ—Ç:")
        logger.info(f"   cat {output_dir}/training_report.txt")

        return True

    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
