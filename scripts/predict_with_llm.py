#!/usr/bin/env python3
"""
–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å LLM –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏
"""

import sys
import os
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append(str(Path(__file__).parent.parent / "src"))

import logging
import pandas as pd
import numpy as np
from typing import Dict, Any, List, Optional
import json

from feature_extractor import FeatureExtractor
from model_trainer import ModelTrainer
from llm_enhancer import LLMFraudEnhancer, MockLLMEnhancer

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def load_llm_enhancer(api_key: Optional[str] = None) -> LLMFraudEnhancer:
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ LLM –µ–Ω—Ö–∞–Ω—Å–µ—Ä–∞

    Args:
        api_key: OpenAI API –∫–ª—é—á (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

    Returns:
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π LLM –µ–Ω—Ö–∞–Ω—Å–µ—Ä
    """
    if api_key:
        logger.info("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM —Å OpenAI API")
        return LLMFraudEnhancer(api_key=api_key)
    else:
        logger.info("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Mock LLM (–¥–µ–º–æ —Ä–µ–∂–∏–º)")
        return MockLLMEnhancer()


def enhance_predictions_with_explanations(
    predictions_df: pd.DataFrame,
    features_df: pd.DataFrame,
    llm_enhancer: LLMFraudEnhancer
) -> pd.DataFrame:
    """
    –î–æ–±–∞–≤–ª–µ–Ω–∏–µ LLM –æ–±—ä—è—Å–Ω–µ–Ω–∏–π –∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º

    Args:
        predictions_df: DataFrame —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
        features_df: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        llm_enhancer: LLM –µ–Ω—Ö–∞–Ω—Å–µ—Ä

    Returns:
        DataFrame —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏
    """
    logger.info("üß† –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—ä—è—Å–Ω–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é LLM...")

    enhanced_df = predictions_df.copy()

    # –°–ø–∏—Å–∫–∏ –¥–ª—è –Ω–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
    explanations = []
    key_factors_list = []
    recommendations_list = []
    confidence_scores = []

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–æ–∫—É
    for idx, row in predictions_df.iterrows():
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_data = {
                'user_id': row.get('user_id', f'user_{idx}'),
                'sample_id': row.get('sample_id', idx)
            }

            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            if idx < len(features_df):
                features = features_df.iloc[idx].to_dict()
                # –£–±–∏—Ä–∞–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è
                features = {k: v for k, v in features.items() if pd.notna(v)}
            else:
                features = {}

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
            fraud_explanation = llm_enhancer.explain_fraud_decision(
                user_data=user_data,
                features=features,
                probability=row['fraud_probability']
            )

            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            explanations.append(fraud_explanation.explanation)
            key_factors_list.append(" | ".join(fraud_explanation.key_factors))
            recommendations_list.append(" | ".join(fraud_explanation.recommendations))
            confidence_scores.append(fraud_explanation.confidence)

            # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            if (idx + 1) % 10 == 0:
                logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {idx + 1}/{len(predictions_df)} –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–æ–∫–∏ {idx}: {e}")
            explanations.append("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ")
            key_factors_list.append("–î–∞–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
            recommendations_list.append("–¢—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞")
            confidence_scores.append(0.5)

    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    enhanced_df['llm_explanation'] = explanations
    enhanced_df['key_factors'] = key_factors_list
    enhanced_df['recommendations'] = recommendations_list
    enhanced_df['explanation_confidence'] = confidence_scores

    logger.info("‚úÖ –û–±—ä—è—Å–Ω–µ–Ω–∏—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ")
    return enhanced_df


def generate_detailed_fraud_report(
    enhanced_predictions: pd.DataFrame,
    llm_enhancer: LLMFraudEnhancer
) -> str:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –æ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–µ

    Args:
        enhanced_predictions: DataFrame —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ –∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏
        llm_enhancer: LLM –µ–Ω—Ö–∞–Ω—Å–µ—Ä

    Returns:
        –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç
    """
    logger.info("üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞...")

    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    fraud_cases = []
    for _, row in enhanced_predictions.iterrows():
        if row['fraud_probability'] > 0.3:  # –¢–æ–ª—å–∫–æ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ª—É—á–∞–∏
            fraud_cases.append({
                'user_id': row['user_id'],
                'probability': row['fraud_probability'],
                'risk_level': row['risk_level'],
                'explanation': row['llm_explanation'],
                'key_factors': row['key_factors']
            })

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç —Å –ø–æ–º–æ—â—å—é LLM
    llm_report = llm_enhancer.generate_fraud_report(fraud_cases)

    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    total_cases = len(enhanced_predictions)
    high_risk_cases = len(enhanced_predictions[enhanced_predictions['fraud_probability'] >= 0.7])
    medium_risk_cases = len(enhanced_predictions[
        (enhanced_predictions['fraud_probability'] >= 0.3) &
        (enhanced_predictions['fraud_probability'] < 0.7)
    ])

    detailed_report = f"""
=== –î–ï–¢–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –ê–ù–¢–ò–§–†–û–î –°–ò–°–¢–ï–ú–´ –° LLM ===
–î–∞—Ç–∞: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}

–°–¢–ê–¢–ò–°–¢–ò–ö–ê:
- –í—Å–µ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {total_cases}
- –í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ (‚â•70%): {high_risk_cases}
- –°—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫ (30-70%): {medium_risk_cases}
- –ù–∏–∑–∫–∏–π —Ä–∏—Å–∫ (<30%): {total_cases - high_risk_cases - medium_risk_cases}

–ê–ù–ê–õ–ò–ó –ü–ê–¢–¢–ï–†–ù–û–í (LLM):
{llm_report}

–¢–û–ü-5 –°–ê–ú–´–• –ü–û–î–û–ó–†–ò–¢–ï–õ–¨–ù–´–• –°–õ–£–ß–ê–ï–í:
"""

    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ø —Å–ª—É—á–∞–∏
    top_cases = enhanced_predictions.nlargest(5, 'fraud_probability')
    for i, (_, case) in enumerate(top_cases.iterrows(), 1):
        detailed_report += f"""
{i}. User {case['user_id']} - –†–∏—Å–∫: {case['fraud_probability']:.1%}
   –û–±—ä—è—Å–Ω–µ–Ω–∏–µ: {case['llm_explanation'][:200]}...
   –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã: {case['key_factors'][:150]}...
   –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: {case['recommendations'][:150]}...
"""

    return detailed_report


def create_interactive_report(enhanced_predictions: pd.DataFrame, output_dir: Path):
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞

    Args:
        enhanced_predictions: DataFrame —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    """
    logger.info("üìã –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞...")

    # HTML –æ—Ç—á–µ—Ç
    html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <title>–ê–Ω—Ç–∏—Ñ—Ä–æ–¥ –û—Ç—á–µ—Ç —Å LLM</title>
    <meta charset="utf-8">
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; }}
        .header {{ background-color: #f0f8ff; padding: 20px; border-radius: 5px; }}
        .risk-high {{ background-color: #ffebee; }}
        .risk-medium {{ background-color: #fff3e0; }}
        .risk-low {{ background-color: #e8f5e8; }}
        .case {{ margin: 10px 0; padding: 15px; border-radius: 5px; border: 1px solid #ddd; }}
        .explanation {{ font-style: italic; color: #555; }}
        .factors {{ color: #333; font-weight: bold; }}
        .recommendations {{ color: #0066cc; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>üõ°Ô∏è –ê–Ω—Ç–∏—Ñ—Ä–æ–¥ –û—Ç—á–µ—Ç —Å LLM –û–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏</h1>
        <p>–î–∞—Ç–∞: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        <p>–í—Å–µ–≥–æ —Å–ª—É—á–∞–µ–≤: {len(enhanced_predictions)}</p>
    </div>

    <h2>üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —É—Ä–æ–≤–Ω—è–º —Ä–∏—Å–∫–∞</h2>
    <ul>
        <li>–í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫: {len(enhanced_predictions[enhanced_predictions['fraud_probability'] >= 0.7])}</li>
        <li>–°—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫: {len(enhanced_predictions[(enhanced_predictions['fraud_probability'] >= 0.3) & (enhanced_predictions['fraud_probability'] < 0.7)])}</li>
        <li>–ù–∏–∑–∫–∏–π —Ä–∏—Å–∫: {len(enhanced_predictions[enhanced_predictions['fraud_probability'] < 0.3])}</li>
    </ul>

    <h2>üö® –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–ª—É—á–∞–µ–≤</h2>
"""

    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–∏
    for _, case in enhanced_predictions.head(20).iterrows():
        risk_class = "risk-high" if case['fraud_probability'] >= 0.7 else "risk-medium" if case['fraud_probability'] >= 0.3 else "risk-low"

        html_content += f"""
    <div class="case {risk_class}">
        <h3>üë§ {case['user_id']} - –†–∏—Å–∫: {case['fraud_probability']:.1%} ({case['risk_level']})</h3>
        <p class="explanation"><strong>–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:</strong> {case['llm_explanation']}</p>
        <p class="factors"><strong>–ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã:</strong> {case['key_factors']}</p>
        <p class="recommendations"><strong>–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:</strong> {case['recommendations']}</p>
        <p><small>–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –æ–±—ä—è—Å–Ω–µ–Ω–∏–∏: {case['explanation_confidence']:.1%}</small></p>
    </div>
"""

    html_content += """
</body>
</html>
"""

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML
    html_file = output_dir / "fraud_report_with_llm.html"
    with open(html_file, 'w', encoding='utf-8') as f:
        f.write(html_content)

    logger.info(f"üíæ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {html_file}")


def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å LLM
    """
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å LLM")

    try:
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
        data_dir = Path(__file__).parent.parent / "data"
        models_dir = Path(__file__).parent.parent / "models"
        output_dir = Path(__file__).parent.parent / "output"

        # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        output_dir.mkdir(exist_ok=True)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ API –∫–ª—é—á–∞
        api_key = os.getenv('OPENAI_API_KEY')
        if api_key:
            logger.info("‚úÖ OpenAI API –∫–ª—é—á –Ω–∞–π–¥–µ–Ω")
        else:
            logger.warning("‚ö†Ô∏è  OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ–º–æ —Ä–µ–∂–∏–º")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º LLM –µ–Ω—Ö–∞–Ω—Å–µ—Ä
        llm_enhancer = load_llm_enhancer(api_key)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        logger.info("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
        model_trainer = ModelTrainer(str(models_dir))
        try:
            model_trainer.load_model("antifraud_model_v1")
        except FileNotFoundError:
            logger.error("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ.")
            return False

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑–≤–ª–µ–∫–∞—Ç–µ–ª—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        logger.info("üìä –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        feature_extractor = FeatureExtractor(str(data_dir))

        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        X_predict = feature_extractor.extract_features()

        if X_predict.empty:
            logger.warning("‚ö†Ô∏è  –î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, —Å–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ...")
            X_predict = feature_extractor.create_sample_features(n_samples=50)

            if 'user_id' in X_predict.columns:
                user_ids = X_predict['user_id'].copy()
                X_predict = X_predict.drop('user_id', axis=1)
            else:
                user_ids = pd.Series([f'test_user_{i}' for i in range(len(X_predict))])
        else:
            if 'user_id' in X_predict.columns:
                user_ids = X_predict['user_id'].copy()
                X_predict = X_predict.drop('user_id', axis=1)
            else:
                user_ids = pd.Series([f'user_{i}' for i in range(len(X_predict))])

        logger.info(f"üìà –î–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {X_predict.shape}")

        # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        logger.info("üîÆ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π...")
        predictions = model_trainer.predict(X_predict)
        probabilities = model_trainer.predict_proba(X_predict)
        fraud_probabilities = probabilities[:, 1]

        # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π DataFrame —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
        basic_predictions = pd.DataFrame({
            'user_id': user_ids.values,
            'sample_id': range(len(X_predict)),
            'prediction': predictions,
            'fraud_probability': fraud_probabilities,
            'risk_level': pd.cut(
                fraud_probabilities,
                bins=[0, 0.3, 0.7, 1.0],
                labels=['–ù–∏–∑–∫–∏–π', '–°—Ä–µ–¥–Ω–∏–π', '–í—ã—Å–æ–∫–∏–π']
            )
        })

        # –î–æ–±–∞–≤–ª—è–µ–º LLM –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
        enhanced_predictions = enhance_predictions_with_explanations(
            basic_predictions, X_predict, llm_enhancer
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        enhanced_file = output_dir / "fraud_predictions_with_llm.csv"
        enhanced_predictions.to_csv(enhanced_file, index=False, encoding='utf-8')
        logger.info(f"üíæ –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {enhanced_file}")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        detailed_report = generate_detailed_fraud_report(enhanced_predictions, llm_enhancer)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        report_file = output_dir / "detailed_fraud_report_llm.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(detailed_report)
        logger.info(f"üìÑ –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}")

        # –°–æ–∑–¥–∞–µ–º –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –æ—Ç—á–µ—Ç
        create_interactive_report(enhanced_predictions, output_dir)

        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        total_cases = len(enhanced_predictions)
        high_risk = len(enhanced_predictions[enhanced_predictions['fraud_probability'] >= 0.7])
        medium_risk = len(enhanced_predictions[
            (enhanced_predictions['fraud_probability'] >= 0.3) &
            (enhanced_predictions['fraud_probability'] < 0.7)
        ])

        logger.info("üìä –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        logger.info(f"   –í—Å–µ–≥–æ —Å–ª—É—á–∞–µ–≤: {total_cases}")
        logger.info(f"   –í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫: {high_risk} ({high_risk/total_cases:.1%})")
        logger.info(f"   –°—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫: {medium_risk} ({medium_risk/total_cases:.1%})")
        logger.info(f"   –ù–∏–∑–∫–∏–π —Ä–∏—Å–∫: {total_cases-high_risk-medium_risk} ({(total_cases-high_risk-medium_risk)/total_cases:.1%})")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
        logger.info("\nüß† –ü—Ä–∏–º–µ—Ä—ã LLM –æ–±—ä—è—Å–Ω–µ–Ω–∏–π:")
        for i, (_, case) in enumerate(enhanced_predictions.head(3).iterrows()):
            logger.info(f"\n{i+1}. User {case['user_id']} (—Ä–∏—Å–∫: {case['fraud_probability']:.1%}):")
            logger.info(f"   –û–±—ä—è—Å–Ω–µ–Ω–∏–µ: {case['llm_explanation'][:150]}...")
            logger.info(f"   –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: {case['recommendations'][:100]}...")

        logger.info("\n‚úÖ –†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å LLM –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        logger.info(f"üéØ –§–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã:")
        logger.info(f"   - CSV —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏: {enhanced_file}")
        logger.info(f"   - –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç: {report_file}")
        logger.info(f"   - HTML –æ—Ç—á–µ—Ç: {output_dir / 'fraud_report_with_llm.html'}")

        return True

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å LLM: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
