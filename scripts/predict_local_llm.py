#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ LLM —á–µ—Ä–µ–∑ Ollama
"""

import sys
import os
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append(str(Path(__file__).parent.parent / "src"))

import logging
import pandas as pd
import numpy as np
from typing import Dict, Any, List, Optional
import json

from feature_extractor import FeatureExtractor
from model_trainer import ModelTrainer
from local_llm_enhancer import LocalLLMEnhancer, OllamaInstaller

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def check_ollama_setup() -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Ollama

    Returns:
        True –µ—Å–ª–∏ Ollama –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
    """
    logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Ollama...")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å—Ç–∞–Ω–æ–≤–∫—É
    if not OllamaInstaller.check_ollama_installed():
        logger.error("‚ùå Ollama –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
        print("\n" + OllamaInstaller.get_installation_instructions())
        return False

    logger.info("‚úÖ Ollama —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")

    # –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –º–æ–¥–µ–ª—å –ø–æ —Ä–µ—Å—É—Ä—Å–∞–º
    recommended_model = OllamaInstaller.recommend_model_by_resources()
    logger.info(f"üí° –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≤–∞—à–µ–π —Å–∏—Å—Ç–µ–º—ã: {recommended_model}")

    return True


def setup_local_llm(model_name: str = "llama3.2:3b") -> Optional[LocalLLMEnhancer]:
    """
    –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π LLM

    Args:
        model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏

    Returns:
        –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π LocalLLMEnhancer –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    try:
        logger.info(f"ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–π LLM: {model_name}")

        # –°–æ–∑–¥–∞–µ–º —ç–Ω—Ö–∞–Ω—Å–µ—Ä
        llm_enhancer = LocalLLMEnhancer(model=model_name)

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
        if llm_enhancer.test_connection():
            logger.info("‚úÖ –õ–æ–∫–∞–ª—å–Ω–∞—è LLM –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
            model_info = llm_enhancer.get_model_info()
            logger.info(f"üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏: {model_info}")

            return llm_enhancer
        else:
            logger.warning("‚ö†Ô∏è  –¢–µ—Å—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –Ω–µ –ø—Ä–æ—à–µ–ª, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback —Ä–µ–∂–∏–º")
            return llm_enhancer

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ –ª–æ–∫–∞–ª—å–Ω–æ–π LLM: {e}")
        return None


def enhance_predictions_with_local_llm(
    predictions_df: pd.DataFrame,
    features_df: pd.DataFrame,
    llm_enhancer: LocalLLMEnhancer
) -> pd.DataFrame:
    """
    –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π –æ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–π LLM –∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º

    Args:
        predictions_df: DataFrame —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
        features_df: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        llm_enhancer: –õ–æ–∫–∞–ª—å–Ω—ã–π LLM –µ–Ω—Ö–∞–Ω—Å–µ—Ä

    Returns:
        DataFrame —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏
    """
    logger.info("üß† –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—ä—è—Å–Ω–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é –ª–æ–∫–∞–ª—å–Ω–æ–π LLM...")

    enhanced_df = predictions_df.copy()

    # –°–ø–∏—Å–∫–∏ –¥–ª—è –Ω–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
    explanations = []
    key_factors_list = []
    recommendations_list = []
    confidence_scores = []

    total_rows = len(predictions_df)

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–æ–∫—É
    for idx, row in predictions_df.iterrows():
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_data = {
                'user_id': row.get('user_id', f'user_{idx}'),
                'sample_id': row.get('sample_id', idx)
            }

            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            if idx < len(features_df):
                features = features_df.iloc[idx].to_dict()
                # –£–±–∏—Ä–∞–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è
                features = {k: v for k, v in features.items() if pd.notna(v)}
            else:
                features = {}

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é –ª–æ–∫–∞–ª—å–Ω–æ–π LLM
            fraud_explanation = llm_enhancer.explain_fraud_decision(
                user_data=user_data,
                features=features,
                probability=row['fraud_probability']
            )

            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            explanations.append(fraud_explanation.explanation)
            key_factors_list.append(" | ".join(fraud_explanation.key_factors))
            recommendations_list.append(" | ".join(fraud_explanation.recommendations))
            confidence_scores.append(fraud_explanation.confidence)

            # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            if (idx + 1) % 5 == 0 or idx + 1 == total_rows:
                progress = (idx + 1) / total_rows * 100
                logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {idx + 1}/{total_rows} ({progress:.1f}%)")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–æ–∫–∏ {idx}: {e}")
            explanations.append("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ")
            key_factors_list.append("–î–∞–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
            recommendations_list.append("–¢—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞")
            confidence_scores.append(0.5)

    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    enhanced_df['local_llm_explanation'] = explanations
    enhanced_df['key_factors'] = key_factors_list
    enhanced_df['recommendations'] = recommendations_list
    enhanced_df['explanation_confidence'] = confidence_scores

    logger.info("‚úÖ –û–±—ä—è—Å–Ω–µ–Ω–∏—è –æ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–π LLM —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ")
    return enhanced_df


def generate_local_fraud_report(
    enhanced_predictions: pd.DataFrame,
    llm_enhancer: LocalLLMEnhancer
) -> str:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–µ —Å –ø–æ–º–æ—â—å—é –ª–æ–∫–∞–ª—å–Ω–æ–π LLM

    Args:
        enhanced_predictions: DataFrame —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ –∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏
        llm_enhancer: –õ–æ–∫–∞–ª—å–Ω—ã–π LLM –µ–Ω—Ö–∞–Ω—Å–µ—Ä

    Returns:
        –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç
    """
    logger.info("üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é –ª–æ–∫–∞–ª—å–Ω–æ–π LLM...")

    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    fraud_cases = []
    for _, row in enhanced_predictions.iterrows():
        if row['fraud_probability'] > 0.3:  # –¢–æ–ª—å–∫–æ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ª—É—á–∞–∏
            fraud_cases.append({
                'user_id': row['user_id'],
                'probability': row['fraud_probability'],
                'risk_level': row['risk_level'],
                'explanation': row['local_llm_explanation'],
                'key_factors': row['key_factors']
            })

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç —Å –ø–æ–º–æ—â—å—é –ª–æ–∫–∞–ª—å–Ω–æ–π LLM
    llm_report = llm_enhancer.generate_fraud_report(fraud_cases)

    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    total_cases = len(enhanced_predictions)
    high_risk_cases = len(enhanced_predictions[enhanced_predictions['fraud_probability'] >= 0.7])
    medium_risk_cases = len(enhanced_predictions[
        (enhanced_predictions['fraud_probability'] >= 0.3) &
        (enhanced_predictions['fraud_probability'] < 0.7)
    ])

    detailed_report = f"""
=== –û–¢–ß–ï–¢ –ê–ù–¢–ò–§–†–û–î –°–ò–°–¢–ï–ú–´ –° –õ–û–ö–ê–õ–¨–ù–û–ô LLM ===
–î–∞—Ç–∞: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}
–ú–æ–¥–µ–ª—å: {llm_enhancer.model}

–°–¢–ê–¢–ò–°–¢–ò–ö–ê:
- –í—Å–µ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {total_cases}
- –í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ (‚â•70%): {high_risk_cases}
- –°—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫ (30-70%): {medium_risk_cases}
- –ù–∏–∑–∫–∏–π —Ä–∏—Å–∫ (<30%): {total_cases - high_risk_cases - medium_risk_cases}

–ê–ù–ê–õ–ò–ó –ü–ê–¢–¢–ï–†–ù–û–í (–õ–æ–∫–∞–ª—å–Ω–∞—è LLM):
{llm_report}

–¢–û–ü-5 –°–ê–ú–´–• –ü–û–î–û–ó–†–ò–¢–ï–õ–¨–ù–´–• –°–õ–£–ß–ê–ï–í:
"""

    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ø —Å–ª—É—á–∞–∏
    top_cases = enhanced_predictions.nlargest(5, 'fraud_probability')
    for i, (_, case) in enumerate(top_cases.iterrows(), 1):
        detailed_report += f"""
{i}. User {case['user_id']} - –†–∏—Å–∫: {case['fraud_probability']:.1%}
   –û–±—ä—è—Å–Ω–µ–Ω–∏–µ: {case['local_llm_explanation'][:200]}...
   –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã: {case['key_factors'][:150]}...
   –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: {case['recommendations'][:150]}...
"""

    return detailed_report


def create_local_llm_html_report(enhanced_predictions: pd.DataFrame, output_dir: Path):
    """
    –°–æ–∑–¥–∞–Ω–∏–µ HTML –æ—Ç—á–µ—Ç–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ª–æ–∫–∞–ª—å–Ω–æ–π LLM

    Args:
        enhanced_predictions: DataFrame —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    """
    logger.info("üìã –°–æ–∑–¥–∞–Ω–∏–µ HTML –æ—Ç—á–µ—Ç–∞...")

    # HTML –æ—Ç—á–µ—Ç
    html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <title>–ê–Ω—Ç–∏—Ñ—Ä–æ–¥ –û—Ç—á–µ—Ç —Å –õ–æ–∫–∞–ª—å–Ω–æ–π LLM</title>
    <meta charset="utf-8">
    <style>
        body {{ font-family: 'Segoe UI', Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }}
        .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                   color: white; padding: 30px; border-radius: 10px; margin-bottom: 20px; }}
        .stats {{ display: flex; justify-content: space-around; margin: 20px 0; }}
        .stat-card {{ background: white; padding: 20px; border-radius: 8px; text-align: center;
                      box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        .stat-number {{ font-size: 2em; font-weight: bold; color: #667eea; }}
        .risk-high {{ background-color: #ffebee; border-left: 4px solid #f44336; }}
        .risk-medium {{ background-color: #fff3e0; border-left: 4px solid #ff9800; }}
        .risk-low {{ background-color: #e8f5e8; border-left: 4px solid #4caf50; }}
        .case {{ margin: 15px 0; padding: 20px; border-radius: 8px;
                 background: white; box-shadow: 0 2px 5px rgba(0,0,0,0.1); }}
        .user-id {{ font-size: 1.2em; font-weight: bold; color: #333; }}
        .probability {{ font-size: 1.1em; font-weight: bold; }}
        .explanation {{ font-style: italic; color: #555; margin: 10px 0;
                       background: #f8f9fa; padding: 15px; border-radius: 5px; }}
        .factors {{ color: #333; font-weight: 500; margin: 10px 0; }}
        .recommendations {{ color: #0066cc; margin: 10px 0;
                           background: #e3f2fd; padding: 10px; border-radius: 5px; }}
        .confidence {{ font-size: 0.9em; color: #666; }}
        .badge {{ padding: 5px 10px; border-radius: 15px; color: white; font-size: 0.9em; }}
        .badge-high {{ background-color: #f44336; }}
        .badge-medium {{ background-color: #ff9800; }}
        .badge-low {{ background-color: #4caf50; }}
        .footer {{ text-align: center; margin-top: 30px; color: #666; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>üõ°Ô∏è –ê–Ω—Ç–∏—Ñ—Ä–æ–¥ –û—Ç—á–µ—Ç —Å –õ–æ–∫–∞–ª—å–Ω–æ–π LLM</h1>
        <p>ü§ñ –ú–æ–¥–µ–ª—å: –õ–æ–∫–∞–ª—å–Ω–∞—è LLM —á–µ—Ä–µ–∑ Ollama</p>
        <p>üìÖ –î–∞—Ç–∞: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
    </div>

    <div class="stats">
        <div class="stat-card">
            <div class="stat-number">{len(enhanced_predictions)}</div>
            <div>–í—Å–µ–≥–æ —Å–ª—É—á–∞–µ–≤</div>
        </div>
        <div class="stat-card">
            <div class="stat-number" style="color: #f44336;">
                {len(enhanced_predictions[enhanced_predictions['fraud_probability'] >= 0.7])}
            </div>
            <div>–í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫</div>
        </div>
        <div class="stat-card">
            <div class="stat-number" style="color: #ff9800;">
                {len(enhanced_predictions[(enhanced_predictions['fraud_probability'] >= 0.3) & (enhanced_predictions['fraud_probability'] < 0.7)])}
            </div>
            <div>–°—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫</div>
        </div>
        <div class="stat-card">
            <div class="stat-number" style="color: #4caf50;">
                {len(enhanced_predictions[enhanced_predictions['fraud_probability'] < 0.3])}
            </div>
            <div>–ù–∏–∑–∫–∏–π —Ä–∏—Å–∫</div>
        </div>
    </div>

    <h2>üö® –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–ª—É—á–∞–µ–≤</h2>
"""

    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–∏ (–ø–µ—Ä–≤—ã–µ 20)
    for _, case in enhanced_predictions.head(20).iterrows():
        risk_class = "risk-high" if case['fraud_probability'] >= 0.7 else "risk-medium" if case['fraud_probability'] >= 0.3 else "risk-low"
        badge_class = "badge-high" if case['fraud_probability'] >= 0.7 else "badge-medium" if case['fraud_probability'] >= 0.3 else "badge-low"

        html_content += f"""
    <div class="case {risk_class}">
        <div class="user-id">üë§ {case['user_id']}</div>
        <div class="probability">
            üìä –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {case['fraud_probability']:.1%}
            <span class="badge {badge_class}">{case['risk_level']}</span>
        </div>
        <div class="explanation">
            <strong>üß† –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω–æ–π LLM:</strong><br>
            {case['local_llm_explanation']}
        </div>
        <div class="factors">
            <strong>üîç –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã:</strong><br>
            {case['key_factors'].replace(' | ', '<br>‚Ä¢ ')}
        </div>
        <div class="recommendations">
            <strong>üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:</strong><br>
            {case['recommendations'].replace(' | ', '<br>‚Ä¢ ')}
        </div>
        <div class="confidence">
            üéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –æ–±—ä—è—Å–Ω–µ–Ω–∏–∏: {case['explanation_confidence']:.1%}
        </div>
    </div>
"""

    html_content += """
    <div class="footer">
        <p>ü§ñ –û—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –ª–æ–∫–∞–ª—å–Ω–æ–π LLM –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤–Ω–µ—à–Ω–∏—Ö API</p>
        <p>üîí –í—Å–µ –¥–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –ª–æ–∫–∞–ª—å–Ω–æ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏</p>
    </div>
</body>
</html>
"""

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML
    html_file = output_dir / "fraud_report_local_llm.html"
    with open(html_file, 'w', encoding='utf-8') as f:
        f.write(html_content)

    logger.info(f"üíæ HTML –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {html_file}")


def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –ª–æ–∫–∞–ª—å–Ω–æ–π LLM
    """
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –ª–æ–∫–∞–ª—å–Ω–æ–π LLM")

    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫—É Ollama
        if not check_ollama_setup():
            return False

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
        data_dir = Path(__file__).parent.parent / "data"
        models_dir = Path(__file__).parent.parent / "models"
        output_dir = Path(__file__).parent.parent / "output"

        # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        output_dir.mkdir(exist_ok=True)

        # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ (–º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å)
        available_models = {
            "1": ("llama3.2:3b", "Llama 3.2 3B - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è (6GB RAM)"),
            "2": ("phi3.5", "Phi-3.5 Mini - –ë—ã—Å—Ç—Ä–∞—è (4GB RAM)"),
            "3": ("qwen2.5:7b", "Qwen 2.5 7B - –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è (8GB RAM)")
        }

        logger.info("ü§ñ –î–æ—Å—Ç—É–ø–Ω—ã–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏:")
        for key, (model, desc) in available_models.items():
            logger.info(f"  {key}. {desc}")

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—É—é –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        selected_model = "llama3.2:3b"
        logger.info(f"üìå –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å: {selected_model}")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–æ–∫–∞–ª—å–Ω—É—é LLM
        llm_enhancer = setup_local_llm(selected_model)
        if not llm_enhancer:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω—É—é LLM")
            return False

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å ML
        logger.info("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ ML –º–æ–¥–µ–ª–∏...")
        model_trainer = ModelTrainer(str(models_dir))
        try:
            model_trainer.load_model("antifraud_model_v1")
        except FileNotFoundError:
            logger.error("‚ùå ML –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ:")
            logger.error("   python3 scripts/main.py --train")
            return False

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑–≤–ª–µ–∫–∞—Ç–µ–ª—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        logger.info("üìä –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        feature_extractor = FeatureExtractor(str(data_dir))

        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        X_predict = feature_extractor.extract_features()

        if X_predict.empty:
            logger.warning("‚ö†Ô∏è  –î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, —Å–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ...")
            X_predict = feature_extractor.create_sample_features(n_samples=30)

            if 'user_id' in X_predict.columns:
                user_ids = X_predict['user_id'].copy()
                X_predict = X_predict.drop('user_id', axis=1)
            else:
                user_ids = pd.Series([f'test_user_{i}' for i in range(len(X_predict))])
        else:
            if 'user_id' in X_predict.columns:
                user_ids = X_predict['user_id'].copy()
                X_predict = X_predict.drop('user_id', axis=1)
            else:
                user_ids = pd.Series([f'user_{i}' for i in range(len(X_predict))])

        logger.info(f"üìà –î–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {X_predict.shape}")

        # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        logger.info("üîÆ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ ML –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π...")
        predictions = model_trainer.predict(X_predict)
        probabilities = model_trainer.predict_proba(X_predict)
        fraud_probabilities = probabilities[:, 1]

        # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π DataFrame —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
        basic_predictions = pd.DataFrame({
            'user_id': user_ids.values,
            'sample_id': range(len(X_predict)),
            'prediction': predictions,
            'fraud_probability': fraud_probabilities,
            'risk_level': pd.cut(
                fraud_probabilities,
                bins=[0, 0.3, 0.7, 1.0],
                labels=['–ù–∏–∑–∫–∏–π', '–°—Ä–µ–¥–Ω–∏–π', '–í—ã—Å–æ–∫–∏–π']
            )
        })

        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –æ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–π LLM
        enhanced_predictions = enhance_predictions_with_local_llm(
            basic_predictions, X_predict, llm_enhancer
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        enhanced_file = output_dir / "fraud_predictions_local_llm.csv"
        enhanced_predictions.to_csv(enhanced_file, index=False, encoding='utf-8')
        logger.info(f"üíæ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –ª–æ–∫–∞–ª—å–Ω–æ–π LLM —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {enhanced_file}")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        detailed_report = generate_local_fraud_report(enhanced_predictions, llm_enhancer)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        report_file = output_dir / "fraud_report_local_llm.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(detailed_report)
        logger.info(f"üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}")

        # –°–æ–∑–¥–∞–µ–º HTML –æ—Ç—á–µ—Ç
        create_local_llm_html_report(enhanced_predictions, output_dir)

        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        total_cases = len(enhanced_predictions)
        high_risk = len(enhanced_predictions[enhanced_predictions['fraud_probability'] >= 0.7])
        medium_risk = len(enhanced_predictions[
            (enhanced_predictions['fraud_probability'] >= 0.3) &
            (enhanced_predictions['fraud_probability'] < 0.7)
        ])

        logger.info("\nüìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        logger.info(f"   –í—Å–µ–≥–æ —Å–ª—É—á–∞–µ–≤: {total_cases}")
        logger.info(f"   üî¥ –í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫: {high_risk} ({high_risk/total_cases:.1%})")
        logger.info(f"   üü° –°—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫: {medium_risk} ({medium_risk/total_cases:.1%})")
        logger.info(f"   üü¢ –ù–∏–∑–∫–∏–π —Ä–∏—Å–∫: {total_cases-high_risk-medium_risk} ({(total_cases-high_risk-medium_risk)/total_cases:.1%})")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
        logger.info("\nüß† –ü–†–ò–ú–ï–†–´ –û–ë–™–Ø–°–ù–ï–ù–ò–ô –û–¢ –õ–û–ö–ê–õ–¨–ù–û–ô LLM:")
        for i, (_, case) in enumerate(enhanced_predictions.head(3).iterrows()):
            logger.info(f"\n{i+1}. üë§ User {case['user_id']} (—Ä–∏—Å–∫: {case['fraud_probability']:.1%}):")
            logger.info(f"   üí≠ –û–±—ä—è—Å–Ω–µ–Ω–∏–µ: {case['local_llm_explanation'][:120]}...")
            logger.info(f"   üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: {case['recommendations'][:80]}...")

        logger.info("\n‚úÖ –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï –° –õ–û–ö–ê–õ–¨–ù–û–ô LLM –ó–ê–í–ï–†–®–ï–ù–û!")
        logger.info(f"üéØ –°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
        logger.info(f"   üìä CSV: {enhanced_file.name}")
        logger.info(f"   üìÑ –û—Ç—á–µ—Ç: {report_file.name}")
        logger.info(f"   üåê HTML: fraud_report_local_llm.html")

        logger.info(f"\nü§ñ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –ª–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å: {llm_enhancer.model}")
        logger.info(f"üîí –í—Å–µ –¥–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –ª–æ–∫–∞–ª—å–Ω–æ –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö API")

        return True

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
