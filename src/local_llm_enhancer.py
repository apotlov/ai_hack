"""
–ú–æ–¥—É–ª—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –ª–æ–∫–∞–ª—å–Ω—ã—Ö LLM –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ Ollama –¥–ª—è –∞–Ω—Ç–∏—Ñ—Ä–æ–¥ —Å–∏—Å—Ç–µ–º—ã
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
import logging
import json
from datetime import datetime
from dataclasses import dataclass
import requests
import time
import re
import subprocess
import os

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class FraudExplanation:
    """
    –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞
    """
    user_id: str
    fraud_probability: float
    risk_level: str
    explanation: str
    key_factors: List[str]
    recommendations: List[str]
    confidence: float


class LocalLLMEnhancer:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –ª–æ–∫–∞–ª—å–Ω—ã—Ö LLM —á–µ—Ä–µ–∑ Ollama
    """

    def __init__(self, model: str = "llama3.2:3b", base_url: str = "http://localhost:11434"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ LLM –µ–Ω—Ö–∞–Ω—Å–µ—Ä–∞

        Args:
            model: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ (llama3.2:3b, phi3.5, qwen2.5:7b)
            base_url: URL Ollama —Å–µ—Ä–≤–µ—Ä–∞
        """
        self.model = model
        self.base_url = base_url
        self.api_url = f"{base_url}/api/generate"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Ollama
        self._check_ollama_status()

        # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞
        self._ensure_model_loaded()

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤
        self.explanation_prompts = {
            "high_risk": """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –±–∞–Ω–∫–æ–≤—Å–∫–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∞–Ω–Ω—ã–µ –∏ –æ–±—ä—è—Å–Ω–∏, –ø–æ—á–µ–º—É —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–∞ –∫–∞–∫ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∞—è.

–î–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:
{user_data}

–ü—Ä–∏–∑–Ω–∞–∫–∏ –º–æ–¥–µ–ª–∏:
{features}

–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞: {probability:.1%}

–î–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç:
1. –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã (2-3 –ø—É–Ω–∫—Ç–∞)
2. –û—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è
3. –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è (–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ)
4. –£—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏

–û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–Ω—è—Ç–µ–Ω –±–∞–Ω–∫–æ–≤—Å–∫–æ–º—É –∞–Ω–∞–ª–∏—Ç–∏–∫—É. –ú–∞–∫—Å–∏–º—É–º 150 —Å–ª–æ–≤.""",

            "pattern_analysis": """–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø–∞—Ç—Ç–µ—Ä–Ω—ã –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞ –≤ –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö.

–î–∞–Ω–Ω—ã–µ –æ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–µ:
{fraud_cases}

–ó–∞–¥–∞—á–∏:
1. –í—ã—è–≤–∏ 3 –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –º–æ—à–µ–Ω–Ω–∏–∫–æ–≤
2. –û–ø—Ä–µ–¥–µ–ª–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã
3. –ù–∞–π–¥–∏ –∞–Ω–æ–º–∞–ª–∏–∏ –≤ –ø–æ–≤–µ–¥–µ–Ω–∏–∏
4. –ü—Ä–µ–¥–ª–æ–∂–∏ 2-3 —É–ª—É—á—à–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏

–§–æ—Ä–º–∞—Ç: —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑, –º–∞–∫—Å–∏–º—É–º 200 —Å–ª–æ–≤."""
        }

    def _check_ollama_status(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ Ollama —Å–µ—Ä–≤–µ—Ä–∞"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            if response.status_code == 200:
                logger.info("‚úÖ Ollama —Å–µ—Ä–≤–µ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω")
                return True
            else:
                logger.warning(f"‚ö†Ô∏è  Ollama —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {response.status_code}")
                return False
        except requests.exceptions.RequestException as e:
            logger.error(f"‚ùå –ù–µ —É–¥–∞–µ—Ç—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Ollama: {e}")
            logger.info("üí° –ó–∞–ø—É—Å—Ç–∏—Ç–µ Ollama: ollama serve")
            return False

    def _ensure_model_loaded(self):
        """–£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
            response = requests.get(f"{self.base_url}/api/tags", timeout=10)
            if response.status_code == 200:
                models_data = response.json()
                available_models = [model['name'] for model in models_data.get('models', [])]

                if self.model not in available_models:
                    logger.warning(f"‚ö†Ô∏è  –ú–æ–¥–µ–ª—å {self.model} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                    logger.info(f"üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {available_models}")

                    # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å
                    logger.info(f"üí° –î–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ: ollama pull {self.model}")

                    # –ü—Ä–æ–±—É–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å
                    self._auto_pull_model()
                else:
                    logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å {self.model} –¥–æ—Å—Ç—É–ø–Ω–∞")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –º–æ–¥–µ–ª–∏: {e}")

    def _auto_pull_model(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""
        try:
            logger.info(f"üîÑ –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å {self.model}...")

            # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏
            result = subprocess.run(['ollama', 'pull', self.model],
                                  capture_output=True, text=True, timeout=300)

            if result.returncode == 0:
                logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å {self.model} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            else:
                logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {result.stderr}")

        except subprocess.TimeoutExpired:
            logger.warning("‚è∞ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∑–∞–Ω—è–ª–∞ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏")
        except FileNotFoundError:
            logger.error("‚ùå Ollama CLI –Ω–µ –Ω–∞–π–¥–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Ollama: https://ollama.ai")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏: {e}")

    def _call_local_llm(self, prompt: str, max_tokens: int = 300) -> str:
        """–í—ã–∑–æ–≤ –ª–æ–∫–∞–ª—å–Ω–æ–π LLM"""
        try:
            payload = {
                "model": self.model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "num_predict": max_tokens,
                    "temperature": 0.3,
                    "top_p": 0.9
                }
            }

            response = requests.post(self.api_url, json=payload, timeout=60)

            if response.status_code == 200:
                result = response.json()
                return result.get('response', '').strip()
            else:
                logger.error(f"–û—à–∏–±–∫–∞ LLM API: {response.status_code}")
                return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏"

        except requests.exceptions.Timeout:
            logger.error("–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ LLM")
            return "–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –º–æ–¥–µ–ª–∏"
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –ª–æ–∫–∞–ª—å–Ω–æ–π LLM: {e}")
            return "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏"

    def explain_fraud_decision(self, user_data: Dict, features: Dict,
                             probability: float) -> FraudExplanation:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Ä–µ—à–µ–Ω–∏—è –æ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–µ

        Args:
            user_data: –î–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            features: –ü—Ä–∏–∑–Ω–∞–∫–∏ –º–æ–¥–µ–ª–∏
            probability: –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞

        Returns:
            –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ—à–µ–Ω–∏—è
        """
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞
            risk_level = self._determine_risk_level(probability)

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–æ–º–ø—Ç
            prompt = self._prepare_explanation_prompt(user_data, features, probability)

            # –ü–æ–ª—É—á–∞–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –æ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–π LLM
            explanation_text = self._call_local_llm(prompt)

            # –ï—Å–ª–∏ LLM –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª–∞
            if "–Ω–µ —É–¥–∞–ª–æ—Å—å" in explanation_text.lower() or "–æ—à–∏–±–∫–∞" in explanation_text.lower():
                explanation_text = self._generate_rule_based_explanation(
                    user_data, features, probability
                )

            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
            explanation = self._parse_explanation(explanation_text)

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã
            key_factors = self._extract_key_factors(features, probability)

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            recommendations = self._generate_recommendations(risk_level, probability)

            return FraudExplanation(
                user_id=user_data.get('user_id', 'unknown'),
                fraud_probability=probability,
                risk_level=risk_level,
                explanation=explanation,
                key_factors=key_factors,
                recommendations=recommendations,
                confidence=self._calculate_confidence(features, probability)
            )

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è: {e}")
            return self._fallback_explanation(user_data, probability)

    def _determine_risk_level(self, probability: float) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è —Ä–∏—Å–∫–∞"""
        if probability >= 0.7:
            return "–í—ã—Å–æ–∫–∏–π"
        elif probability >= 0.3:
            return "–°—Ä–µ–¥–Ω–∏–π"
        else:
            return "–ù–∏–∑–∫–∏–π"

    def _prepare_explanation_prompt(self, user_data: Dict, features: Dict,
                                  probability: float) -> str:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è LLM"""

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_summary = self._format_user_data(user_data)

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–æ–ø –ø—Ä–∏–∑–Ω–∞–∫–∏
        top_features = self._format_top_features(features)

        return self.explanation_prompts["high_risk"].format(
            user_data=user_summary,
            features=top_features,
            probability=probability
        )

    def _format_user_data(self, user_data: Dict) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞"""
        formatted = []

        if 'user_id' in user_data:
            formatted.append(f"ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_data['user_id']}")

        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        for key, value in user_data.items():
            if key != 'user_id' and value is not None:
                formatted.append(f"{key}: {value}")

        return "\n".join(formatted) if formatted else "–ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ"

    def _format_top_features(self, features: Dict, top_n: int = 8) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ–ø –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        if not features:
            return "–ü—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ –¥–æ—Å—Ç—É–ø–Ω—ã"

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ –∞–±—Å–æ–ª—é—Ç–Ω–æ–º—É –∑–Ω–∞—á–µ–Ω–∏—é
        sorted_features = sorted(
            features.items(),
            key=lambda x: abs(x[1]) if isinstance(x[1], (int, float)) else 0,
            reverse=True
        )

        formatted = []
        for feature, value in sorted_features[:top_n]:
            if isinstance(value, (int, float)):
                # –ü–µ—Ä–µ–≤–æ–¥–∏–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –≤ –ø–æ–Ω—è—Ç–Ω—ã–µ
                readable_name = self._make_feature_readable(feature)
                formatted.append(f"{readable_name}: {value:.3f}")
            else:
                formatted.append(f"{feature}: {value}")

        return "\n".join(formatted)

    def _make_feature_readable(self, feature_name: str) -> str:
        """–ü–µ—Ä–µ–≤–æ–¥ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –ø–æ–Ω—è—Ç–Ω—ã–µ"""
        translations = {
            'amplitude_night_activity_ratio': '–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –Ω–æ—á—å—é (%)',
            'amplitude_session_count': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ—Å—Å–∏–π',
            'amplitude_avg_session_duration': '–°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ—Å—Å–∏–∏ (—Å–µ–∫)',
            'amplitude_unique_event_types': '–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –¥–µ–π—Å—Ç–≤–∏–π',
            'amplitude_weekend_ratio': '–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤ –≤—ã—Ö–æ–¥–Ω—ã–µ (%)',
            'audio_mfcc_0_mean': '–¢–æ–Ω –≥–æ–ª–æ—Å–∞ (–∞—É–¥–∏–æ)',
            'audio_spectral_centroid_mean': '–ö–∞—á–µ—Å—Ç–≤–æ —Ä–µ—á–∏ (–∞—É–¥–∏–æ)',
            'audio_rms_mean': '–ì—Ä–æ–º–∫–æ—Å—Ç—å –≥–æ–ª–æ—Å–∞',
            'audio_duration': '–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–∞–ø–∏—Å–∏ (—Å–µ–∫)'
        }

        # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if feature_name in translations:
            return translations[feature_name]

        # –ò—â–µ–º —á–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        for key, translation in translations.items():
            if key in feature_name:
                return translation

        # –£–ø—Ä–æ—â–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
        simplified = feature_name.replace('_', ' ').replace('amplitude', '–ø–æ–≤–µ–¥–µ–Ω–∏–µ').replace('audio', '–∞—É–¥–∏–æ')
        return simplified.title()

    def _parse_explanation(self, explanation_text: str) -> str:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –æ—Ç LLM"""
        # –ü—Ä–æ—Å—Ç–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
        cleaned = explanation_text.strip()

        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
        cleaned = re.sub(r'\n+', ' ', cleaned)
        cleaned = re.sub(r'\s+', ' ', cleaned)

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
        if len(cleaned) > 500:
            cleaned = cleaned[:497] + "..."

        return cleaned

    def _extract_key_factors(self, features: Dict, probability: float) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤"""
        factors = []

        if not features:
            return [f"–û–±—â–∞—è –º–æ–¥–µ–ª—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {probability:.1%}"]

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
        sorted_features = sorted(
            features.items(),
            key=lambda x: abs(x[1]) if isinstance(x[1], (int, float)) else 0,
            reverse=True
        )

        for feature, value in sorted_features[:5]:
            if isinstance(value, (int, float)) and abs(value) > 0.01:
                readable_name = self._make_feature_readable(feature)
                factors.append(f"{readable_name}: {value:.2f}")

        if not factors:
            factors.append(f"–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏: {probability:.1%}")

        return factors

    def _generate_recommendations(self, risk_level: str, probability: float) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        recommendations = []

        if risk_level == "–í—ã—Å–æ–∫–∏–π":
            recommendations.extend([
                "–ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏",
                "–°–≤—è–∑–∞—Ç—å—Å—è —Å –∫–ª–∏–µ–Ω—Ç–æ–º –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è",
                "–ü—Ä–æ–≤–µ—Å—Ç–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤",
                "–£–≤–µ–¥–æ–º–∏—Ç—å —Å–ª—É–∂–±—É –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"
            ])
        elif risk_level == "–°—Ä–µ–¥–Ω–∏–π":
            recommendations.extend([
                "–£—Å–∏–ª–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–ø–µ—Ä–∞—Ü–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è",
                "–ó–∞–ø—Ä–æ—Å–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—é",
                "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –æ–ø–µ—Ä–∞—Ü–∏–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞"
            ])
        else:
            recommendations.extend([
                "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥",
                "–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å —Å—Ç–∞—Ç—É—Å"
            ])

        return recommendations

    def _calculate_confidence(self, features: Dict, probability: float) -> float:
        """–†–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏"""
        confidence = 0.6  # –ë–∞–∑–æ–≤–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–∏ –∫—Ä–∞–π–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏—è—Ö
        if probability > 0.8 or probability < 0.2:
            confidence += 0.2

        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        if features:
            important_features = sum(
                1 for value in features.values()
                if isinstance(value, (int, float)) and abs(value) > 0.1
            )
            confidence += min(important_features * 0.03, 0.2)

        return min(confidence, 1.0)

    def _generate_rule_based_explanation(self, user_data: Dict, features: Dict,
                                       probability: float) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∞–≤–∏–ª (fallback)"""
        explanations = []

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        for feature, value in features.items():
            if not isinstance(value, (int, float)):
                continue

            if 'night_activity' in feature and value > 0.3:
                explanations.append(f"–í—ã—Å–æ–∫–∞—è –Ω–æ—á–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å ({value:.1%})")

            if 'session_count' in feature and value < 5:
                explanations.append(f"–ú–∞–ª–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ—Å—Å–∏–π ({value:.0f})")

            if 'session_duration' in feature and value < 60:
                explanations.append(f"–ö–æ—Ä–æ—Ç–∫–∏–µ —Å–µ—Å—Å–∏–∏ ({value:.0f} —Å–µ–∫)")

        if probability > 0.8:
            explanations.append("–ö—Ä–∞–π–Ω–µ –≤—ã—Å–æ–∫–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞")
        elif probability > 0.5:
            explanations.append("–ü–æ–≤—ã—à–µ–Ω–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞")

        if not explanations:
            explanations.append("–ú–æ–¥–µ–ª—å –≤—ã—è–≤–∏–ª–∞ –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–≤–µ–¥–µ–Ω–∏—è")

        return ". ".join(explanations) + "."

    def _fallback_explanation(self, user_data: Dict, probability: float) -> FraudExplanation:
        """Fallback –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö"""
        return FraudExplanation(
            user_id=user_data.get('user_id', 'unknown'),
            fraud_probability=probability,
            risk_level=self._determine_risk_level(probability),
            explanation=f"–ú–æ–¥–µ–ª—å –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞ {probability:.1%} –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤.",
            key_factors=[f"–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏: {probability:.1%}"],
            recommendations=self._generate_recommendations(self._determine_risk_level(probability), probability),
            confidence=0.5
        )

    def generate_fraud_report(self, fraud_cases: List[Dict]) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–µ —Å –ø–æ–º–æ—â—å—é –ª–æ–∫–∞–ª—å–Ω–æ–π LLM

        Args:
            fraud_cases: –°–ø–∏—Å–æ–∫ —Å–ª—É—á–∞–µ–≤ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞

        Returns:
            –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç
        """
        if not fraud_cases:
            return "–°–ª—É—á–∞–µ–≤ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ."

        try:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            patterns = self._analyze_fraud_patterns(fraud_cases)

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç —Å –ø–æ–º–æ—â—å—é –ª–æ–∫–∞–ª—å–Ω–æ–π LLM
            prompt = self.explanation_prompts["pattern_analysis"].format(
                fraud_cases=json.dumps(patterns, ensure_ascii=False, indent=2)
            )

            llm_report = self._call_local_llm(prompt, max_tokens=400)

            # –ï—Å–ª–∏ LLM –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª–∞
            if "–Ω–µ —É–¥–∞–ª–æ—Å—å" in llm_report.lower() or "–æ—à–∏–±–∫–∞" in llm_report.lower():
                llm_report = self._generate_rule_based_report(patterns)

            return llm_report

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")
            return f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(fraud_cases)} —Å–ª—É—á–∞–µ–≤ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏. –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑."

    def _analyze_fraud_patterns(self, fraud_cases: List[Dict]) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞"""
        patterns = {
            "total_cases": len(fraud_cases),
            "avg_probability": np.mean([case.get('probability', 0) for case in fraud_cases]),
            "high_risk_count": sum(1 for case in fraud_cases if case.get('probability', 0) > 0.7),
            "risk_distribution": {
                "high": sum(1 for case in fraud_cases if case.get('probability', 0) > 0.7),
                "medium": sum(1 for case in fraud_cases if 0.3 <= case.get('probability', 0) <= 0.7),
                "low": sum(1 for case in fraud_cases if case.get('probability', 0) < 0.3)
            }
        }

        return patterns

    def _generate_rule_based_report(self, patterns: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∞–≤–∏–ª"""
        report_parts = []

        report_parts.append(f"–û–¢–ß–ï–¢ –û –ú–û–®–ï–ù–ù–ò–ß–ï–°–¢–í–ï")
        report_parts.append(f"–î–∞—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
        report_parts.append("")

        report_parts.append(f"–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        report_parts.append(f"- –í—Å–µ–≥–æ —Å–ª—É—á–∞–µ–≤: {patterns['total_cases']}")
        report_parts.append(f"- –°—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {patterns['avg_probability']:.1%}")
        report_parts.append(f"- –í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫: {patterns['high_risk_count']}")

        if 'risk_distribution' in patterns:
            dist = patterns['risk_distribution']
            report_parts.append(f"- –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: –í—ã—Å–æ–∫–∏–π({dist['high']}) –°—Ä–µ–¥–Ω–∏–π({dist['medium']}) –ù–∏–∑–∫–∏–π({dist['low']})")

        report_parts.append("")

        report_parts.append("–û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã:")
        if patterns['high_risk_count'] > patterns['total_cases'] * 0.3:
            report_parts.append("- –í—ã—Å–æ–∫–∞—è –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–µ–≤ –≤—ã—Å–æ–∫–æ–≥–æ —Ä–∏—Å–∫–∞")
        report_parts.append("- –¢—Ä–µ–±—É–µ—Ç—Å—è –∞–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")
        report_parts.append("- –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –∞–Ω–æ–º–∞–ª–∏–π")
        report_parts.append("")

        report_parts.append("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        if patterns['high_risk_count'] > 0:
            report_parts.append("- –ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–ª—É—á–∞–∏ –≤—ã—Å–æ–∫–æ–≥–æ —Ä–∏—Å–∫–∞")
        report_parts.append("- –£—Å–∏–ª–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π")
        report_parts.append("- –û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–∞–≤–∏–ª–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏")

        return "\n".join(report_parts)

    def get_model_info(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models_data = response.json()
                for model in models_data.get('models', []):
                    if model['name'] == self.model:
                        return {
                            'name': model['name'],
                            'size': model.get('size', 'unknown'),
                            'modified_at': model.get('modified_at', 'unknown'),
                            'status': 'available'
                        }
            return {'name': self.model, 'status': 'not_found'}
        except:
            return {'name': self.model, 'status': 'ollama_unavailable'}

    def test_connection(self) -> bool:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é"""
        try:
            test_prompt = "–°–∫–∞–∂–∏ '—Ç–µ—Å—Ç –ø—Ä–æ—à–µ–ª —É—Å–ø–µ—à–Ω–æ' –µ—Å–ª–∏ —Ç—ã —Ä–∞–±–æ—Ç–∞–µ—à—å."
            response = self._call_local_llm(test_prompt, max_tokens=50)

            if response and "—Ç–µ—Å—Ç –ø—Ä–æ—à–µ–ª" in response.lower():
                logger.info("‚úÖ –õ–æ–∫–∞–ª—å–Ω–∞—è LLM —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
                return True
            else:
                logger.warning(f"‚ö†Ô∏è  –ü–æ–ª—É—á–µ–Ω –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç: {response}")
                return False

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
            return False


class OllamaInstaller:
    """
    –ü–æ–º–æ—â–Ω–∏–∫ –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Ollama
    """

    @staticmethod
    def check_ollama_installed() -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ Ollama"""
        try:
            result = subprocess.run(['ollama', '--version'],
                                  capture_output=True, text=True)
            return result.returncode == 0
        except FileNotFoundError:
            return False

    @staticmethod
    def get_installation_instructions() -> str:
        """–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ Ollama"""
        return """
üöÄ –£–°–¢–ê–ù–û–í–ö–ê OLLAMA –î–õ–Ø –õ–û–ö–ê–õ–¨–ù–´–• LLM

1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Ollama:
   macOS/Linux: curl -fsSL https://ollama.ai/install.sh | sh
   Windows: –°–∫–∞—á–∞–π—Ç–µ —Å https://ollama.ai/download

2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–µ—Ä–≤–µ—Ä:
   ollama serve

3. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—É—é –º–æ–¥–µ–ª—å:
   ollama pull llama3.2:3b

4. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏:
   ollama pull phi3.5        # –ë—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å (4GB)
   ollama pull qwen2.5:7b    # –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å (8GB)

5. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç–∞—Ç—É—Å:
   ollama list

–ì–æ—Ç–æ–≤–æ! –õ–æ–∫–∞–ª—å–Ω–∞—è LLM –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞.
"""

    @staticmethod
    def recommend_model_by_resources() -> str:
        """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –ø–æ —Ä–µ—Å—É—Ä—Å–∞–º"""
        import psutil

        ram_gb = psutil.virtual_memory().total / (1024**3)

        if ram_gb >= 16:
            return "qwen2.5:7b (–ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ, 8GB)"
        elif ram_gb >= 8:
            return "llama3.2:3b (–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –≤—ã–±–æ—Ä, 6GB)"
        else:
            return "phi3.5 (—ç–∫–æ–Ω–æ–º–∏—á–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç, 4GB)"
