#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω—Ç–∏—Ñ—Ä–æ–¥ —Å–∏—Å—Ç–µ–º—ã
–ü–æ–º–æ–∂–µ—Ç –ø–æ–¥–∫–ª—é—á–∏—Ç—å –≤–∞—à–∏ Parquet –∏ WAV —Ñ–∞–π–ª—ã
"""

import sys
import os
from pathlib import Path
import pandas as pd
import numpy as np
import shutil
import logging
from typing import Dict, List, Optional

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class DataPreparer:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    """

    def __init__(self, base_dir: str = "."):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è

        Args:
            base_dir: –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞
        """
        self.base_dir = Path(base_dir)
        self.data_dir = self.base_dir / "data"
        self.amplitude_dir = self.data_dir / "amplitude"
        self.audio_dir = self.data_dir / "audio"

        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self.amplitude_dir.mkdir(parents=True, exist_ok=True)
        self.audio_dir.mkdir(parents=True, exist_ok=True)

    def check_data_structure(self) -> Dict:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –¥–∞–Ω–Ω—ã—Ö
        """
        logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö...")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º Parquet —Ñ–∞–π–ª—ã
        parquet_files = list(self.amplitude_dir.glob("*.parquet"))

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—É–¥–∏–æ —Ñ–∞–π–ª—ã
        audio_extensions = ["*.wav", "*.mp3", "*.flac", "*.m4a"]
        audio_files = []
        for ext in audio_extensions:
            audio_files.extend(list(self.audio_dir.glob(ext)))

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º targets
        targets_file = self.data_dir / "targets.csv"

        info = {
            "parquet_files": len(parquet_files),
            "parquet_list": [f.name for f in parquet_files],
            "audio_files": len(audio_files),
            "audio_list": [f.name for f in audio_files[:5]],  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
            "has_targets": targets_file.exists(),
            "targets_path": str(targets_file)
        }

        return info

    def validate_parquet_files(self) -> bool:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è Parquet —Ñ–∞–π–ª–æ–≤

        Returns:
            True –µ—Å–ª–∏ —Ñ–∞–π–ª—ã –≤–∞–ª–∏–¥–Ω—ã
        """
        logger.info("üìä –í–∞–ª–∏–¥–∞—Ü–∏—è Parquet —Ñ–∞–π–ª–æ–≤...")

        parquet_files = list(self.amplitude_dir.glob("*.parquet"))

        if not parquet_files:
            logger.warning("‚ö†Ô∏è  Parquet —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return False

        required_columns = ["user_id"]
        recommended_columns = ["event_time", "event_type"]

        all_valid = True

        for file_path in parquet_files:
            try:
                logger.info(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª: {file_path.name}")

                # –ß–∏—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫
                df = pd.read_parquet(file_path, nrows=100)

                logger.info(f"  –†–∞–∑–º–µ—Ä: {len(df)} —Å—Ç—Ä–æ–∫ (–ø–µ—Ä–≤—ã–µ 100)")
                logger.info(f"  –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
                missing_required = [col for col in required_columns if col not in df.columns]
                if missing_required:
                    logger.error(f"  ‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {missing_required}")
                    all_valid = False
                else:
                    logger.info("  ‚úÖ –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –Ω–∞–π–¥–µ–Ω—ã")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏
                missing_recommended = [col for col in recommended_columns if col not in df.columns]
                if missing_recommended:
                    logger.warning(f"  ‚ö†Ô∏è  –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {missing_recommended}")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ
                if df.empty:
                    logger.error(f"  ‚ùå –§–∞–π–ª –ø—É—Å—Ç–æ–π")
                    all_valid = False

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º user_id
                if "user_id" in df.columns:
                    unique_users = df["user_id"].nunique()
                    logger.info(f"  üë• –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {unique_users}")

                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö
                logger.info("  üìã –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö:")
                logger.info(f"     {df.head(2).to_dict('records')}")

            except Exception as e:
                logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {file_path.name}: {e}")
                all_valid = False

        return all_valid

    def validate_audio_files(self) -> bool:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤

        Returns:
            True –µ—Å–ª–∏ —Ñ–∞–π–ª—ã –≤–∞–ª–∏–¥–Ω—ã
        """
        logger.info("üéµ –í–∞–ª–∏–¥–∞—Ü–∏—è –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤...")

        audio_extensions = ["*.wav", "*.mp3", "*.flac", "*.m4a"]
        audio_files = []
        for ext in audio_extensions:
            audio_files.extend(list(self.audio_dir.glob(ext)))

        if not audio_files:
            logger.warning("‚ö†Ô∏è  –ê—É–¥–∏–æ —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return False

        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(audio_files)} –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤
        sample_files = audio_files[:5]  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 5

        try:
            import librosa

            for audio_file in sample_files:
                try:
                    logger.info(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª: {audio_file.name}")

                    # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª
                    y, sr = librosa.load(str(audio_file), sr=None, duration=1.0)

                    logger.info(f"  üìè –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: ~{len(y)/sr:.1f} —Å–µ–∫")
                    logger.info(f"  üîä –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏: {sr} Hz")
                    logger.info(f"  üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {audio_file.stat().st_size / 1024:.1f} KB")

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º user_id –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                    user_id = self._extract_user_id_from_filename(audio_file.stem)
                    logger.info(f"  üë§ –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π user_id: {user_id}")

                except Exception as e:
                    logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {audio_file.name}: {e}")
                    return False

            logger.info("‚úÖ –ê—É–¥–∏–æ —Ñ–∞–π–ª—ã –ø—Ä–æ—à–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é")
            return True

        except ImportError:
            logger.error("‚ùå –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ librosa –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
            return False

    def _extract_user_id_from_filename(self, filename: str) -> str:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ user_id –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞

        Args:
            filename: –ò–º—è —Ñ–∞–π–ª–∞ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è

        Returns:
            –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π user_id
        """
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        if '_' in filename:
            parts = filename.split('_')
            if len(parts) >= 2:
                return parts[0]  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —á—Ç–æ user_id –≤ –Ω–∞—á–∞–ª–µ

        # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
        return filename

    def validate_targets(self) -> bool:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–π–ª–∞ —Å —Ü–µ–ª–µ–≤—ã–º–∏ –º–µ—Ç–∫–∞–º–∏

        Returns:
            True –µ—Å–ª–∏ —Ñ–∞–π–ª –≤–∞–ª–∏–¥–µ–Ω
        """
        logger.info("üéØ –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–π–ª–∞ —Å —Ü–µ–ª–µ–≤—ã–º–∏ –º–µ—Ç–∫–∞–º–∏...")

        targets_file = self.data_dir / "targets.csv"

        if not targets_file.exists():
            logger.warning("‚ö†Ô∏è  –§–∞–π–ª targets.csv –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return False

        try:
            df = pd.read_csv(targets_file)

            logger.info(f"üìè –†–∞–∑–º–µ—Ä: {len(df)} –∑–∞–ø–∏—Å–µ–π")
            logger.info(f"üìä –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            required_columns = ["user_id", "is_fraud"]
            missing_columns = [col for col in required_columns if col not in df.columns]

            if missing_columns:
                logger.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {missing_columns}")
                return False

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è is_fraud
            fraud_values = df["is_fraud"].unique()
            if not all(val in [0, 1] for val in fraud_values):
                logger.error(f"‚ùå –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è is_fraud: {fraud_values}")
                return False

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            fraud_count = df["is_fraud"].sum()
            fraud_rate = fraud_count / len(df)

            logger.info(f"üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞:")
            logger.info(f"  –í—Å–µ–≥–æ —Å–ª—É—á–∞–µ–≤: {len(df)}")
            logger.info(f"  –ú–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ: {fraud_count} ({fraud_rate:.1%})")
            logger.info(f"  –õ–µ–≥–∏—Ç–∏–º–Ω—ã–µ: {len(df) - fraud_count} ({1-fraud_rate:.1%})")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä
            logger.info("üìã –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö:")
            logger.info(f"   {df.head(3).to_dict('records')}")

            logger.info("‚úÖ –§–∞–π–ª —Å —Ü–µ–ª–µ–≤—ã–º–∏ –º–µ—Ç–∫–∞–º–∏ –≤–∞–ª–∏–¥–µ–Ω")
            return True

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ targets.csv: {e}")
            return False

    def create_sample_data(self, n_users: int = 100):
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

        Args:
            n_users: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        """
        logger.info(f"üß™ –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {n_users} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π...")

        np.random.seed(42)

        # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä Amplitude –¥–∞–Ω–Ω—ã—Ö
        sample_amplitude = []

        for user_id in range(1, n_users + 1):
            n_events = np.random.randint(5, 50)  # 5-50 —Å–æ–±—ã—Ç–∏–π –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

            for event_id in range(n_events):
                event_data = {
                    "user_id": f"user_{user_id}",
                    "event_time": pd.Timestamp("2024-01-01") + pd.Timedelta(
                        days=np.random.randint(0, 90),
                        hours=np.random.randint(0, 24),
                        minutes=np.random.randint(0, 60)
                    ),
                    "event_type": np.random.choice([
                        "login", "transaction", "logout", "view_balance",
                        "transfer", "payment", "profile_update"
                    ]),
                    "session_duration": np.random.exponential(300),  # –°—Ä–µ–¥–Ω–µ–µ 5 –º–∏–Ω—É—Ç
                    "click_count": np.random.poisson(10),
                    "page_views": np.random.poisson(5),
                    "device_type": np.random.choice(["mobile", "desktop", "tablet"]),
                    "amount": np.random.lognormal(3, 1) if np.random.random() < 0.3 else None
                }
                sample_amplitude.append(event_data)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º Amplitude –¥–∞–Ω–Ω—ã–µ
        df_amplitude = pd.DataFrame(sample_amplitude)
        amplitude_file = self.amplitude_dir / "sample_amplitude_data.parquet"
        df_amplitude.to_parquet(amplitude_file, index=False)

        logger.info(f"üíæ –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª: {amplitude_file}")
        logger.info(f"   –ó–∞–ø–∏—Å–µ–π: {len(df_amplitude)}")
        logger.info(f"   –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {df_amplitude['user_id'].nunique()}")

        # –°–æ–∑–¥–∞–µ–º —Ü–µ–ª–µ–≤—ã–µ –º–µ—Ç–∫–∏
        fraud_rate = 0.15  # 15% –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞

        targets_data = []
        for user_id in range(1, n_users + 1):
            is_fraud = 1 if np.random.random() < fraud_rate else 0
            targets_data.append({
                "user_id": f"user_{user_id}",
                "is_fraud": is_fraud
            })

        df_targets = pd.DataFrame(targets_data)
        targets_file = self.data_dir / "targets.csv"
        df_targets.to_csv(targets_file, index=False)

        logger.info(f"üíæ –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª: {targets_file}")
        logger.info(f"   –ó–∞–ø–∏—Å–µ–π: {len(df_targets)}")
        logger.info(f"   –ú–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ: {df_targets['is_fraud'].sum()} ({df_targets['is_fraud'].mean():.1%})")

        logger.info("‚úÖ –ü—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö —Å–æ–∑–¥–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ!")

    def copy_external_data(self, external_data_path: str):
        """
        –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–Ω–µ—à–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö –≤ –ø—Ä–æ–µ–∫—Ç

        Args:
            external_data_path: –ü—É—Ç—å –∫ –≤–Ω–µ—à–Ω–∏–º –¥–∞–Ω–Ω—ã–º
        """
        external_path = Path(external_data_path)

        if not external_path.exists():
            logger.error(f"‚ùå –ü—É—Ç—å –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {external_data_path}")
            return

        logger.info(f"üìÇ –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑: {external_data_path}")

        # –ö–æ–ø–∏—Ä—É–µ–º Parquet —Ñ–∞–π–ª—ã
        parquet_files = list(external_path.glob("**/*.parquet"))
        for file_path in parquet_files:
            dest_path = self.amplitude_dir / file_path.name
            shutil.copy2(file_path, dest_path)
            logger.info(f"‚úÖ –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω: {file_path.name}")

        # –ö–æ–ø–∏—Ä—É–µ–º –∞—É–¥–∏–æ —Ñ–∞–π–ª—ã
        audio_extensions = ["*.wav", "*.mp3", "*.flac", "*.m4a"]
        for ext in audio_extensions:
            audio_files = list(external_path.glob(f"**/{ext}"))
            for file_path in audio_files:
                dest_path = self.audio_dir / file_path.name
                shutil.copy2(file_path, dest_path)
                logger.info(f"‚úÖ –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω: {file_path.name}")

        # –ö–æ–ø–∏—Ä—É–µ–º targets.csv –µ—Å–ª–∏ –µ—Å—Ç—å
        targets_files = list(external_path.glob("**/targets.csv"))
        if targets_files:
            dest_path = self.data_dir / "targets.csv"
            shutil.copy2(targets_files[0], dest_path)
            logger.info(f"‚úÖ –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω: targets.csv")

    def generate_report(self) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –¥–∞–Ω–Ω—ã—Ö

        Returns:
            –¢–µ–∫—Å—Ç –æ—Ç—á–µ—Ç–∞
        """
        info = self.check_data_structure()

        report = ["=" * 60]
        report.append("üìä –û–¢–ß–ï–¢ –û –î–ê–ù–ù–´–• –ê–ù–¢–ò–§–†–û–î –°–ò–°–¢–ï–ú–´")
        report.append("=" * 60)
        report.append("")

        # Parquet –¥–∞–Ω–Ω—ã–µ
        report.append("üìà AMPLITUDE –î–ê–ù–ù–´–ï (Parquet):")
        if info["parquet_files"] > 0:
            report.append(f"  ‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {info['parquet_files']}")
            for filename in info["parquet_list"]:
                report.append(f"     - {filename}")
        else:
            report.append("  ‚ùå Parquet —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        report.append("")

        # –ê—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ
        report.append("üéµ –ê–£–î–ò–û –î–ê–ù–ù–´–ï:")
        if info["audio_files"] > 0:
            report.append(f"  ‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {info['audio_files']}")
            for filename in info["audio_list"]:
                report.append(f"     - {filename}")
            if info["audio_files"] > 5:
                report.append(f"     ... –∏ –µ—â–µ {info['audio_files'] - 5} —Ñ–∞–π–ª–æ–≤")
        else:
            report.append("  ‚ùå –ê—É–¥–∏–æ —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        report.append("")

        # –¶–µ–ª–µ–≤—ã–µ –º–µ—Ç–∫–∏
        report.append("üéØ –¶–ï–õ–ï–í–´–ï –ú–ï–¢–ö–ò:")
        if info["has_targets"]:
            report.append(f"  ‚úÖ –§–∞–π–ª –Ω–∞–π–¥–µ–Ω: {info['targets_path']}")
        else:
            report.append("  ‚ùå –§–∞–π–ª targets.csv –Ω–µ –Ω–∞–π–¥–µ–Ω")
        report.append("")

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        report.append("üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        if info["parquet_files"] == 0:
            report.append("  ‚Ä¢ –î–æ–±–∞–≤—å—Ç–µ Parquet —Ñ–∞–π–ª—ã –≤ data/amplitude/")
        if info["audio_files"] == 0:
            report.append("  ‚Ä¢ –î–æ–±–∞–≤—å—Ç–µ –∞—É–¥–∏–æ —Ñ–∞–π–ª—ã –≤ data/audio/")
        if not info["has_targets"]:
            report.append("  ‚Ä¢ –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª data/targets.csv —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏: user_id, is_fraud")

        if info["parquet_files"] > 0 or info["audio_files"] > 0:
            report.append("  ‚Ä¢ –ó–∞–ø—É—Å—Ç–∏—Ç–µ –≤–∞–ª–∏–¥–∞—Ü–∏—é: python prepare_data.py --validate")
            report.append("  ‚Ä¢ –ù–∞—á–Ω–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ: python scripts/main.py --train")

        report.append("")
        report.append("=" * 60)

        return "\n".join(report)


def main():
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
    """
    import argparse

    parser = argparse.ArgumentParser(
        description="–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω—Ç–∏—Ñ—Ä–æ–¥ —Å–∏—Å—Ç–µ–º—ã",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python prepare_data.py --check               # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
  python prepare_data.py --validate            # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
  python prepare_data.py --create-sample       # –°–æ–∑–¥–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö
  python prepare_data.py --copy /path/to/data  # –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –≤–Ω–µ—à–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ
  python prepare_data.py --report              # –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á–µ—Ç
        """
    )

    parser.add_argument("--check", action="store_true", help="–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö")
    parser.add_argument("--validate", action="store_true", help="–í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ")
    parser.add_argument("--create-sample", action="store_true", help="–°–æ–∑–¥–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö")
    parser.add_argument("--copy", type=str, help="–°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤–Ω–µ—à–Ω–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞")
    parser.add_argument("--report", action="store_true", help="–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á–µ—Ç")
    parser.add_argument("--users", type=int, default=100, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è –ø—Ä–∏–º–µ—Ä–æ–≤")

    args = parser.parse_args()

    # –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ
    print("=" * 60)
    print("üìä –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø –ê–ù–¢–ò–§–†–û–î –°–ò–°–¢–ï–ú–´")
    print("=" * 60)
    print()

    preparer = DataPreparer()

    try:
        if args.check:
            info = preparer.check_data_structure()
            print("üîç –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:")
            print(f"  Parquet —Ñ–∞–π–ª–æ–≤: {info['parquet_files']}")
            print(f"  –ê—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤: {info['audio_files']}")
            print(f"  –¶–µ–ª–µ–≤—ã–µ –º–µ—Ç–∫–∏: {'‚úÖ' if info['has_targets'] else '‚ùå'}")

        elif args.validate:
            print("üîç –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏...")

            parquet_valid = preparer.validate_parquet_files()
            audio_valid = preparer.validate_audio_files()
            targets_valid = preparer.validate_targets()

            print("\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –í–ê–õ–ò–î–ê–¶–ò–ò:")
            print(f"  Parquet —Ñ–∞–π–ª—ã: {'‚úÖ' if parquet_valid else '‚ùå'}")
            print(f"  –ê—É–¥–∏–æ —Ñ–∞–π–ª—ã: {'‚úÖ' if audio_valid else '‚ùå'}")
            print(f"  –¶–µ–ª–µ–≤—ã–µ –º–µ—Ç–∫–∏: {'‚úÖ' if targets_valid else '‚ùå'}")

            if all([parquet_valid, audio_valid, targets_valid]):
                print("\nüéâ –í—Å–µ –¥–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è!")
                print("–ó–∞–ø—É—Å—Ç–∏—Ç–µ: python scripts/main.py --train")
            else:
                print("\n‚ö†Ô∏è  –ï—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã —Å –¥–∞–Ω–Ω—ã–º–∏, –∏—Å–ø—Ä–∞–≤—å—Ç–µ –∏—Ö –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º")

        elif args.create_sample:
            preparer.create_sample_data(n_users=args.users)

        elif args.copy:
            preparer.copy_external_data(args.copy)

        elif args.report:
            report = preparer.generate_report()
            print(report)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç –≤ —Ñ–∞–π–ª
            report_file = Path("data_report.txt")
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"\nüíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {report_file}")

        else:
            # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç—á–µ—Ç
            report = preparer.generate_report()
            print(report)

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return 1

    return 0


if __name__ == "__main__":
    sys.exit(main())
